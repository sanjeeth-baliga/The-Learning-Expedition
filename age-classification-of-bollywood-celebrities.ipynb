{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction","metadata":{}},{"cell_type":"markdown","source":"**Quick description**\n\nThe code that follows deploys an ensemble of pre-trained computer vision neural network models that are fine-tuned to the task of age classification of bollywood celebrities into YOUNG, MIDDLE and OLD classes from their facial images. The solution is highly inspired from a course on deep learning offered by fastai ([reference](https://www.kaggle.com/code/jhoward/first-steps-road-to-the-top-part-1)) and has been built by using kaggle notebook\n\n","metadata":{}},{"cell_type":"markdown","source":"**Dataset reference**\n\nThe dataset used for the task has been taken from a practice challenge on the analytics vidya portal and linked [here](https://datahack.analyticsvidhya.com/contest/practice-problem-age-detection/#About). Once the data is downloaded, make sure that you unzip the training and test data sets along with storing their respective folders in a local directory.\n\nPlease assign the name of this local directory to the **input path** variable as shown in the following line\n\n***input_path = '/kaggle/input/age-estimate' (<-- replace this path)***\n\nPlease ensure that the GPU accelerators are activated for the training operation to ensure that the training time is reasonable","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom pathlib import Path\nfrom fastai.vision.all import *\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport shutil","metadata":{"execution":{"iopub.status.busy":"2023-07-09T13:04:01.132479Z","iopub.execute_input":"2023-07-09T13:04:01.132738Z","iopub.status.idle":"2023-07-09T13:04:11.148665Z","shell.execute_reply.started":"2023-07-09T13:04:01.132713Z","shell.execute_reply":"2023-07-09T13:04:11.147575Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Organization of the training and test data sets","metadata":{}},{"cell_type":"markdown","source":"The original training dataset can be **split into train, validation and a holdout data sets** for the purpose of the learning and performance measurement. The holdout dataset would be used only at a final stage to determine the accuracy of the model and the potential for it to generalize on a population of the facial image data set","metadata":{}},{"cell_type":"markdown","source":"The model has been designed using fastai which requires **training images to be organized across folders representing their respective class labels**. Hence the first step would involve reorganization of the input image files in a suitable folder structure using the steps detailed below","metadata":{}},{"cell_type":"markdown","source":"1.  Create file path pointers to extract the training images from the inputs and display a sample image to ensure that the internal library stack is functioning as per the expectation","metadata":{}},{"cell_type":"code","source":"input_path = '/kaggle/input/age-estimate'\npath = Path(input_path)\ntrain_path = (path/'train')\ntrn_images_path = (train_path/'Train')\ntrn_images = get_image_files(trn_images_path)\nim = PILImage.create(trn_images[1])\nprint(im.size)\nim.to_thumb(128)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T13:04:11.150571Z","iopub.execute_input":"2023-07-09T13:04:11.150878Z","iopub.status.idle":"2023-07-09T13:04:28.072110Z","shell.execute_reply.started":"2023-07-09T13:04:11.150851Z","shell.execute_reply":"2023-07-09T13:04:28.071157Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"(69, 70)\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=69x70>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAEUAAABGCAIAAAAVe87QAAATjUlEQVR4nK1baXfcyG69WIrslrV47PG8vP//x5IPOUneEo9lqdVkFYB8QLGaasmzvJM6Ou1eSBZ2XABl+nj/GQAAIspXDgAQYgARERH5DRERkaoCIA5VncukqiJERFMpzFyYZFvEEUSqGoSxxdViZhEZr0TEKgCEy+FwmOeZmQEGwMwR4Q53jwgAhLyS3b21ZmburvjByns6Ea9/YmYWSPKxkXVFaBfQdmtEEFG+vt1r/2WnlYiZVXWaJiIBYGZX/CAYgIqYWd7yW/y4e5J+xQ8RiUiZREQYlB9VVVK6vOcNkRresfSj7d6qrm9UikiJiOQngtw9aQsnALS793f0c7HAHR3MXEqZJmVmCqQUSymISH6GuoAQok2YXQm/wVXngZiEk7iIYGZmNrN5nvf8uHvyY60lVfmEH/JztdNGIlQ1GRAReDCzqqiqm6VOLsaW3gcgQESISMFQgLD9BRg0/kDEzEzdKIR5nibh0qip6hU/7oiIbZu+fsjPlUsMl1XVdHdVZeT3xMzhvucnIoDk5SKUvXKuFJXv+bXdqerhcCg611pTXRG00zMiopSyJ/uH/IgI3nhndxWR/KaIMqeqsYWBGOT29xf2Xvn9lf73r8wc0W9JObbWtnsv3EZ0g3wl99/Vz56lHoi3jbuW+NVDYrMy7CzhR7sMDsczlSUf6O5mZma11nVdr26M12swquPDcD7Zolb+JCKzllLK4LCUMs2qqt1ImFWVpsndo9UkIiJAfiV12p6ZfiJEyizMQiRERZVEzIwjik7TNMHj+7fHeT6qaribWY8BtdV1jSBVrbWKSCYfvLW3iMAb7Xc+RdKmh/9IOi51o04/uygHSDHvfQab57y7NFW9+WpenIrK18w5G/V9LzNrrS3LYmZ6pfG9vUUPwZc1bCwXI29xbPmO3pgWBRABSgYDFESABwvtI1v+je2EWIkFxAHyANxbC3cg0geEiMAigqBa68vLy+Pj4/l8fsXP5tPvWPnbXyP9MSLCAFhrEUFuw7jT3vAm4VxFuVdu4EFCY8eRJLDFpwQn3c5JRZXda63Lsjw+Pj49PemIYxcD2yE3vPHp1HtriAiKRB8WEchwFH5F/VsBjYDr7mkF+5VfvpXjdterED8i1rqup9Pp+/fv19GJKFMIdUwRwZtLxIbB3L21MDP4RT+6g3N97y6AS/DZx9Z3hZUPf/trfswcSht0uLorvUj3eabrJ5nyS8bYvyZN+YjkB3AiMjNm5h2U3r8ZbLxFrldrXIDXwQCAmQFMr1NImmIpZZqmeZ517Hcxua6kSxJ0Qmxk9PxDPiSXCjUz90bcYX86T0QUUbx2zivqR6QhkpSmEHfEmFKDJdERgQETAS6qqo4obZrneT4cDsuiHBe32ymRgpDo0oG1tSACqJRSax3GyRmpKf0192HiGKgHILPWfwkwWJmEmJndXYQKl6JlQ+iFCcosLMoiqoUlNj0vrSa0CwIIIqJTIZXldFpaNXcIayk6JHSVa/d5o6seYeFbjAaA6D6St6SvBPULKOP4FQDZaXXv2ZKGRIRwj0T+Hh3PgYJQtDAzSCLCwi18Wddm5oR1XV/WJSK4qDJn0UJA+hk2f/WdmLslu5ODh81sjhed/lfLd28o+YpddnrtJwZQhAG9OGO5SJZAxIRuxt15WmstnIgM8evjt6/ffm2tsYqOQnd4ETZstjG2A2PmTp0akG8BDwHrdkCI6JvuNfBWP2O7NAQz67y5pXXk4uC0g6xz0m+bW2vNWrTw0+n0t7/97evXr6WU4/Go0mvKDgEDW+iQiwaSZHg43AlEFDC6NqVO7ggtSTRfNIAIjojI0AmJCPeWcTiDGGeRCIBq16c1goDJKTM4uXu1tq5rXW219vXr12/fH5dlwVab6SXjbqlmH+56MXgR7CXzUr4n7/CeAuDNwN5h9UpFl04AmJkTWTKFiHC1JCyYEOwInSd3bxZmlvws57q0+nR6VtWPHz9u5Vnp8aDrZwOLIx6YBQzuicN6bdlj65Y36XXlkwrcGEneEq14RxERHhbuCBrml5AXWdJwT/QtPJwsfDoekp8sTM1sXdpqTVU///Ll48ePtdbn5+cO+/PmDKP7RIFdzt4LOz0LIOJAUIShNyccSGv8oYqGNaayh/6zT5B1Lqhn+epmLSxczy/u7kFExCrDng+Hw5cvX3755ZenpydmVg4U1VJKRLTWLE2bJXtuEcEsWnjsuqXwyHiIyCKnW5Ft+DevybcAIpp72rOIhDtF0KXPZBERpZTD4SCq8zw3i2/fvr28vARTOC11PfiNuxPr8Xi8u7u7v78/Hj6Qyoe727uPD9ktqbXqu62zoZx9CLrK7gCI09ay/iHA4QhYSj2/h8XQDBG11ogaEbW2kw66zZdS5mkqpVC1LLS4qHCZ42CIUoqW+ebm5vb29uHh4eH+p/nmSMLlMJvZsiyn00mZM7VnKZpdF2Tm2cxjbzAgAvOGnTqV2PBJhutNVek3m54BhF+AZrbTmHs3QkSmuQT8cDhM0yRqy7JEBKnM05GEDSEiWubEaaOmfHx5ttPz8/Pzr7/++vj4qPs257sWH7tyckhURAAnYsA7AINHMJG5U68gAABmfnGe2KOQVyArItZ1PZ/P/JFF5CDl7u6OmQ1RdEolEBFLKaVM88zM67q28NPysqzr8/PzsiwiohTIv94JlEsCvWxG7OSeGLQbB4AOpkWSH7qkFiTdAxSPKBIg5AOy65kyHpVzrfV8PhNR6sHMllbNLNwyXgf4cDgcj8fD4RBOy7J8+/btvCyJKud51n3CHiX7SD7j16Gf5CftE2HMwkwigt5hyq7vrv9Wbe8/zMykRKQ6AZim6ebmRnVqrWWT7enpaV3XaT5msHX31tzCZS1mxmKqOq1zRCzn+vRy+ufjr82slHJ/f393d6cRkVhj4Ha8aWJk+dHZo83RASIeN0b2u0UiLELQESr0hmPrPqefCHdATUSHw83Dw8PhcDifz4+PT6fT6fn5+XQ6sTxnPHBCOAX13Ghm5/M5i9Tzy/p8fuG5TCIfPnz48uXL58+f1d1ZECEBI1IWhBMLCAzycAI5BREHBYE8m7G78EBMxER+qZ0Y6Aokomk6jHkGEpLIJCLTNAE4Hm/u7u4Oh4OIPD8/m9la14T/pZR5nqdpYp1EJJqBiUEZlyPCo4mIebZLPDt1am0NT6TPYS5CzEq0IbbMlUEUzkQAJ8br5ALwcG9es3/p0QcM2rt4REJZDqkIb7GEmYkFEVHr8v37t9bW1lqEZakryuwgCoSFtzByb+7Wwo1Yqk6HuZRCSkV0Uvlwd3s8Hpf15d//46u2tm6wTXuA7c5jI7YOB0tzAxDUDTKARNwDJTE4OMKZmEE9sTLrcNHuRERpP8uyDOlGBDoxHeC11thAROfz2RAgkXkiYS4qKSFiANl/O51O2lrjfRNw6whjB0/GGwD0uhM9kFvy03vZvI0QMuhdj5EuYDf9YVlq+j0zJ7aIzVuwFVLVWgsnVmWa3ZEdLObRUej9kPT1FG3eH7vicc9JF/D2/eA5r3X3HsTTWLsU3IwGAhnRZR8hIsK9v1dVy9z1ioAIgkwF7qP/Rpv8YutB5DDignf20WyfW/fp6M3al83pbBGwCNn42drVHfXx6Ne1molYB7RPPtd2JiJnigAREzMRE0AiIAL4XQBARNlhvww/9gnnXawwbv3xL9nWEVysNEiVtyFxmmAKyM1z36Sju5Db1gcl76Vjz3u1Vo8IFsrGIMEiuHeSe0EtIsqysUoRvT7ZJmpXtHZ1XdxgaAabi2x+4hvdBMBBtmXXABzsQHA4wRBCYFZmWFRY5Dy8F4iB0dZsntCfHGG49OXm4zSyGREpvTGtkcvftTq+Hhn5YDjh9pXShn+O5yQSHX1Md+/FXnqjMAf71r7LZQhidsS+mxmtEdGNSI7BeTPf/qhRYBKN13c8J/Wz8bxxztHMOXiDQsN/QDFagTBL5xRmdrd+tVMinZrLWnVDhBTN2ZZZmBmLQBgkFn46ndZWjx8+zMdDUpXBgJn/0Dz4NT8XHWLXP9i+9K20xojIqY2I6BPcrVeBzQoiorV2Pp+XumY2U5Z5ng/TLCLuaGbrukI4wBZwt7W1OL80t5ub2z4+y/Hen+fngi97JulRzofsI5z6qIurVUAIxCKqxMzChZmn6ZCoR0Qi8PLystSKWlurzEyqzMwqLAKDAKpqiNasWm1urKoRRFRrba0lnvot/fwwTL/OSNk/GLrag4l0QJGOPqdpylKs6KyqqhNvM7/WjLYWnJ2eUl2JG4jIWrTWnFCtnZe6WiPh44cPic2xOWGCCd01Mv+gfnYfaLSmfIMCEeHDxzKMJt2qOk/H4+E4TYd+BGPTcASSYXdf2lpbs+a2rjnWdkOGcke4Q0TKPB2Px2mapGivZ7s9/4HzO1eLid/85KOtgDd4L0coOSROwyCq7n44HFI6EZHsTdPkwNRWYjYyIio5Toe4ewtnFS2zHKZ5nnkqIkLCnTGRzFF/2n/QK4P+YUR1HoEyOpQkDoZaRDg4gppLMbEWLBye8wJhzVwupUiZxWyaJlWlA6nqcZ5LKZQQWYWERSeaVFWdKSIygsdWQZjZn+ZnD1XfYQvAOMriFAx2csTW65JEJMz8cjqrail5wIPzIEvzKGUCIFLmeb45HKdpIiILL9NhWF1zZxZVBZNVGx3w1pricmLoQhkRuf8gHvBu5hWX2s4GbggEMVgAEQiRaOIRCCyiubEHwwAikUJLbevSzufzujaCaOkNW2I5tfayxWJZ83wQJThw9BZATlBGyfjn7e2Ha9/7pggC2EAMZCM1ArlrQoCIFhHZv+yJ1MwRTMqiUoqqgijzrJmtvmyC9mz6doQtJbaxpJnpu37/m5j6/TViAHYhoUcFAnWkY601i2ECTtXcfW016ePt0EOGuwDWdU2WymEG4Ii03gGjahuzFY9xvmon2lfl2p/iZy+IfYjDDpRnrIiIaZos3Ne1tba2mlFOVXmXTzzCtlWSvI5q44qfARH0ioh/gZPf5bMbBjOYxwYWHh6t+lLXPG6UeJm0ZONirRVZSLdq4cuyEFFOFtJVOkIhMev88Cjrr9TyL9gbbd1T2rW5xxve1kDHlobUfF3XdV1TP9UNWmi3ABgiGcuIk/yk9oiEyBPyABCR984j/Uv2Nm6h1wvCIIr8y0DkXcYAzNFaW61FhBO04nw+5wFYZoZcquusFpHDRxJQn6btU0X3n/8ve7tiCTvljKxl4a31sxygDIN78XGtBtjWE++MBYCtLB3enzeoyggGInId3/Zock/lFZ97kQxadx3W/RzBVHUq04hjrfla6+l0ygIsT2pktczMrTXWQsQWEAerBGDNpkl0KolrzuvaT2ACKlPWujkh/qP550p1v63JoRNmnhOzEPXeZ2u1+TiU4eO0QiJXkZubQ9Hp0vQQ7rGLSVXneTazPDOYPZ083z7K8t/nJ161pujVxx9ykhOEPqNhEfdYW315eWmt5UyXVDyc8lSwMJOASUSSMtbtyC1zrdWx9SJFeMPs2UsRlowlSdv7+XRP3xVLVz9dXXwVzUaTYBwDbW6JkrYDB0FEDBk1+ZhxXKQj/fpaK7aqNq83M9jlxPzv19tXysF1KL9YHb239j8hs7s7EweTNyOiIBAorBcUxnb74Z5EmTlBUx4RdIODl2rNF1VlLYVlXddaW+3n5rNVwr+ln3c52ZvcW+XsBbGXcSmcR9C3EXU/fxL06nRYC39+OWWTMa8fx9etrqMVkfaWGmtrxe70zG/p561ycG1y18yP60cV1FqToiyiU8n/LxIkNM43cG+eJHoAsCyLiJdSSin9tLp7RGStSuPo3Q55YN9P/A1+8F4c+1FkE7z63ySdnwhbVyk6TZcuGViJaG2WGcazoRfEIsT6cPdAUvKInsyTEb3U5fvLWqurqqgEuLWWXDEIwoJLuNfBN3Y+gGs/2fGzaYO4/0eDrEv7LAie/xKRuWe8bmsNcyI6Ho8AwMpaHFxb3NzcLqtPZf705ZfDfPPw0ycws0ptVkr5z//+L2b+vv59ocVVWbiBvTZenTjC3N1FJJyChHVikevzvb+jrnx9fVWOUjO7kZMhPIiZgyBbOs9an4lJRXQiKYfj3Vq9lGOLl5AyTbcPHz9/+eWv95/uZSrfHp+en5/n78+3t7fQOUS9tVbP68vJbS0qB2UBV6+2I56u+r1v195t3l656ZAGP+nTyY9sODKfU4QljxCWifVwe3t7XppDAy9EMh0PD59++uXf/jLf3kzznIHq7u7ur3/9688///zTTw9Pj4/ffv3nP/5nPS3PTBApyv3Anm8zjO4/e1feq+st9RvOy2F27+2PPNvnmG4eFBEk7O5LXZubhTeKmQgmELDby3I+nWtAl1anw+2Hu9sPt/fTYeZ+FFNuH+5/bvXTp08RcX9/+8+///14nLyu1s6EIAgpiYmZj4EaM+sfMbMfraGfiKB3+lgAsLTG7tVd3WvEBC8GlvJS23lprAcw3T3cf/r8+eb2gxM+HI/ruso0/+XTZ5GiZWq23t/fh1kp7OtS1/Pp6Xt/ujBszDLwyt6uuHobFeJiXtvpqCtH2sABtv+lY4iIqK01s4YIpiA0I3CbPNYWx0KHw+Hhp4+fPn06fLjBdqQiiG9ubo43Nz3nlDLPM3B3/unz/379R13OwdE7FsHZikgz+T9tpvMswr7zWwAAAABJRU5ErkJggg==\n"},"metadata":{}}]},{"cell_type":"markdown","source":"2. The dataset also consists of a csv file which indicates the mapping between each image file and the corresponding age class label. The set of **mappings can be split into training samples and holdout samples**.","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(train_path/'train.csv')\nX_train,X_test,y_train,y_test = train_test_split(train_df['ID'],train_df['Class'],test_size=0.25,stratify=train_df['Class'].to_list())\nX_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-09T13:04:28.075080Z","iopub.execute_input":"2023-07-09T13:04:28.075390Z","iopub.status.idle":"2023-07-09T13:04:28.146151Z","shell.execute_reply.started":"2023-07-09T13:04:28.075365Z","shell.execute_reply":"2023-07-09T13:04:28.145206Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"3094     2697.jpg\n7694    10088.jpg\n4712    18084.jpg\n3684    12043.jpg\n6542     6666.jpg\nName: ID, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"3. The image samples corresponding to the **holdout set** (called as test set) can be **copied to a separate location** for measuring performance later on. When running it locally, **users can set the test_path to a directory path of their choice**. The copy function of the shutil library can be used to perform the copy operation","metadata":{}},{"cell_type":"code","source":"test_path = Path('/kaggle/working/test')\ntest_path.mkdir(exist_ok=True)\nfor img in X_test.to_list():\n    src_path = (trn_images_path/img)\n    dest_path = test_path\n    shutil.copy(src_path,dest_path)\nprint('Done')","metadata":{"execution":{"iopub.status.busy":"2023-07-09T13:04:28.148962Z","iopub.execute_input":"2023-07-09T13:04:28.149310Z","iopub.status.idle":"2023-07-09T13:04:55.756976Z","shell.execute_reply.started":"2023-07-09T13:04:28.149261Z","shell.execute_reply":"2023-07-09T13:04:55.755945Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Done\n","output_type":"stream"}]},{"cell_type":"markdown","source":"4. As a part of the setup for the training procedure, a **folder structure** can be created comprising of **one folder store each for the age class labels**. Users can **set the new_path variable** to any local directory path of their choice","metadata":{}},{"cell_type":"code","source":"new_path = Path('/kaggle/working/')\nnew_path = (new_path/'train')\nnew_path.mkdir(exist_ok=True)\nclass_names = train_df['Class'].unique().tolist()\n\nfor cn in class_names:\n    dst_path = (new_path/cn)\n    dst_path.mkdir(exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T13:04:55.758585Z","iopub.execute_input":"2023-07-09T13:04:55.759555Z","iopub.status.idle":"2023-07-09T13:04:55.772564Z","shell.execute_reply.started":"2023-07-09T13:04:55.759521Z","shell.execute_reply":"2023-07-09T13:04:55.771609Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"5. The training image files can be copied now from the inputs folder to their respective age group folders","metadata":{}},{"cell_type":"code","source":"for i,img in enumerate(X_train.to_list()):\n    src_path = (trn_images_path/img)\n    dst_path = (new_path/y_train.iloc[i])\n    shutil.copy(src_path,dst_path)\nprint('Done')","metadata":{"execution":{"iopub.status.busy":"2023-07-09T13:04:55.774425Z","iopub.execute_input":"2023-07-09T13:04:55.775354Z","iopub.status.idle":"2023-07-09T13:06:21.765825Z","shell.execute_reply.started":"2023-07-09T13:04:55.775242Z","shell.execute_reply":"2023-07-09T13:06:21.764848Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Done\n","output_type":"stream"}]},{"cell_type":"code","source":"trn_images_path = new_path\ntrn_images = get_image_files(trn_images_path)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T13:06:21.767310Z","iopub.execute_input":"2023-07-09T13:06:21.767676Z","iopub.status.idle":"2023-07-09T13:06:22.089954Z","shell.execute_reply.started":"2023-07-09T13:06:21.767644Z","shell.execute_reply":"2023-07-09T13:06:22.088985Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# The Training Approach","metadata":{}},{"cell_type":"markdown","source":"1. A quick code snippet can help in determination of the image size distribution. This is helpful to get a sense of the pre-processing transformations that can be applied before subjecting the image pixels to computer vision learning algorithms","metadata":{}},{"cell_type":"code","source":"from fastcore.parallel import *\ndef sizing(o): return PILImage.create(o).size\nimg_sizing = parallel(sizing,trn_images,n_workers=8)\npd.Series(img_sizing).value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-07-09T13:06:22.091419Z","iopub.execute_input":"2023-07-09T13:06:22.091845Z","iopub.status.idle":"2023-07-09T13:06:49.866255Z","shell.execute_reply.started":"2023-07-09T13:06:22.091813Z","shell.execute_reply":"2023-07-09T13:06:49.865171Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(36, 56)      42\n(37, 54)      35\n(26, 36)      17\n(29, 39)      16\n(30, 44)      14\n              ..\n(91, 95)       1\n(96, 92)       1\n(110, 108)     1\n(144, 209)     1\n(116, 157)     1\nLength: 8370, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"2. For ease of reusability, the entire training logic has been wrapped in a function which leverages fastai libraries for the following purposes:\n    * The **ImageDataLoaders class** can be used to translate the image pixels into suitable batches for training the learning algorithms that leverage computer vision architectures. The **pre-processing stages of resizing and augmentation** are also applied to the training images at this point in time so that the **learning algorithms develop invariance** to operations such as flipping, rotation, resizing, lighting changes, etc.\n    * The **arch function parameter** is used to indicate the **pre-trained computer vision architecture** of a model that can be fine-tuned to the specific task of age classification. In fine-tuning, all the layers in the a given model are not subjected to the training procedure. Only **the head of the model (the last layer)** is trained for updating the associated activations to the task under consideration\n    * A **vision_learner object** of the fastai library can be used as an abstraction layer to orchestrate the entire training procedure given suitable values for dataloaders, metrics, number of epochs and learning rate\n    * **Gradient Accumulation** has been leveraged in the model to ensure that the **limited GPU memory is efficiently used** even with achieving larger effective batch sizes (In this case, the gradients are accumulated for the accum number of training steps instead of being reset to zero after each training step)\n    * **Test time augmentation** (tta) is applied on the test/holdout dataset while determining the likelihood of each age category to improve the accuracy of classification","metadata":{}},{"cell_type":"code","source":"def create_learner(arch,test_images,item_tfms=Resize(64,method='squish'),size = 64,epoch=5,bs=128,\n                  accum=1,fine_tune=True):\n    img_dls = ImageDataLoaders.from_folder(trn_images_path,valid_pct=0.25,item_tfms = item_tfms,\n                                           batch_tfms = aug_transforms(size=size,min_scale=0.75),bs=bs//accum)\n    cbs=GradientAccumulation(bs) if accum else []\n    learner = vision_learner(img_dls,arch,metrics=error_rate,path='.',cbs=cbs).to_fp16()\n    if fine_tune:\n        learner.fine_tune(epoch,1e-2)\n        return learner.tta(dl=learner.dls.test_dl(test_images))\n    else:\n        learner.unfreeze()\n        learner.fit_one_cycle(epoch,1e-2)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T13:06:49.867658Z","iopub.execute_input":"2023-07-09T13:06:49.868025Z","iopub.status.idle":"2023-07-09T13:06:49.876509Z","shell.execute_reply.started":"2023-07-09T13:06:49.867990Z","shell.execute_reply":"2023-07-09T13:06:49.875430Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"3. An ensemble of models corresponding to the computer vision architectures of **resnet, convnext and vit** have been leveraged for improving the accuracy of age classification. A dictionary corresponding to the architecture checkpoints discussed above and their suitable preprocessing steps can be used to achieve the ensemble learning operation","metadata":{}},{"cell_type":"code","source":"model_archs={\n    'vit_base_patch32_224':{(Resize(224,method='squish'),224)},\n    'convnext_small_in22k':{(Resize(64,method='crop'),64)},\n    'resnet26d':{(Resize((128,48),method=ResizeMethod.Pad,pad_mode=PadMode.Zeros),128)}\n}","metadata":{"execution":{"iopub.status.busy":"2023-07-09T13:06:49.880207Z","iopub.execute_input":"2023-07-09T13:06:49.880562Z","iopub.status.idle":"2023-07-09T13:06:49.892407Z","shell.execute_reply.started":"2023-07-09T13:06:49.880531Z","shell.execute_reply":"2023-07-09T13:06:49.891588Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"4. The **likelihood of age category prediction** obtained on the test/holdout data from training the learner with each of the **computer vision models** discussed earlier can be stored within the tta_preds list. The vision models corresponding to the various architectures are trained on invocation of the create_learner function","metadata":{"execution":{"iopub.status.busy":"2023-06-29T04:06:24.247784Z","iopub.execute_input":"2023-06-29T04:06:24.250591Z","iopub.status.idle":"2023-06-29T04:06:24.590798Z","shell.execute_reply.started":"2023-06-29T04:06:24.250559Z","shell.execute_reply":"2023-06-29T04:06:24.589947Z"}}},{"cell_type":"code","source":"import gc\ntest_images = get_image_files(test_path)\ntta_preds=[]\nfor arch,model_config in model_archs.items():\n    for it_config,b_size in model_config:\n        print(f'---{arch}')\n        tta_preds.append(create_learner(arch=arch,test_images=test_images,item_tfms=it_config,\n                            size = b_size,epoch=6,bs=128,accum=2))\n        gc.collect()\n        torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-07-09T13:06:49.893635Z","iopub.execute_input":"2023-07-09T13:06:49.894235Z","iopub.status.idle":"2023-07-09T13:26:21.537437Z","shell.execute_reply.started":"2023-07-09T13:06:49.894203Z","shell.execute_reply":"2023-07-09T13:26:21.536298Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"---vit_base_patch32_224\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de486f98486e4f3c8add2794bf5a5c72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>error_rate</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.799465</td>\n      <td>0.654585</td>\n      <td>0.252144</td>\n      <td>00:49</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>error_rate</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.529594</td>\n      <td>0.444388</td>\n      <td>0.177385</td>\n      <td>00:49</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.467745</td>\n      <td>0.392407</td>\n      <td>0.152197</td>\n      <td>00:48</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.373987</td>\n      <td>0.412893</td>\n      <td>0.162915</td>\n      <td>00:49</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.249990</td>\n      <td>0.326172</td>\n      <td>0.114952</td>\n      <td>00:48</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.170600</td>\n      <td>0.277375</td>\n      <td>0.098339</td>\n      <td>00:49</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.128895</td>\n      <td>0.279947</td>\n      <td>0.098071</td>\n      <td>00:48</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      <progress value='0' class='' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    \n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"---convnext_small_in22k\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/timm/models/_factory.py:114: UserWarning: Mapping deprecated model name convnext_small_in22k to current convnext_small.fb_in22k.\n  model = create_fn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7513bdce9efa455c8e36520f67495604"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>error_rate</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.879887</td>\n      <td>0.757710</td>\n      <td>0.285102</td>\n      <td>00:35</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>error_rate</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.649176</td>\n      <td>0.578344</td>\n      <td>0.229904</td>\n      <td>00:40</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.597208</td>\n      <td>0.544382</td>\n      <td>0.204180</td>\n      <td>00:40</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.505389</td>\n      <td>0.476329</td>\n      <td>0.188639</td>\n      <td>00:40</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.416057</td>\n      <td>0.407254</td>\n      <td>0.159432</td>\n      <td>00:42</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.357772</td>\n      <td>0.397391</td>\n      <td>0.155681</td>\n      <td>00:40</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.320371</td>\n      <td>0.387572</td>\n      <td>0.153269</td>\n      <td>00:53</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      <progress value='0' class='' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    \n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"---resnet26d\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/64.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"242ce318f00a49f583a1079f5d014fb1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>error_rate</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.162088</td>\n      <td>0.903574</td>\n      <td>0.407556</td>\n      <td>00:45</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>error_rate</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.889139</td>\n      <td>0.790403</td>\n      <td>0.351822</td>\n      <td>00:45</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.851702</td>\n      <td>0.774945</td>\n      <td>0.328242</td>\n      <td>00:46</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.821372</td>\n      <td>0.737682</td>\n      <td>0.322883</td>\n      <td>00:45</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.760975</td>\n      <td>0.673610</td>\n      <td>0.291533</td>\n      <td>00:46</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.721261</td>\n      <td>0.665561</td>\n      <td>0.284566</td>\n      <td>00:45</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.687496</td>\n      <td>0.644856</td>\n      <td>0.277063</td>\n      <td>00:46</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      <progress value='0' class='' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    \n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"markdown","source":"# Accuracy determination on the holdout dataset","metadata":{"execution":{"iopub.status.busy":"2023-06-29T04:24:38.479448Z","iopub.execute_input":"2023-06-29T04:24:38.479981Z","iopub.status.idle":"2023-06-29T04:24:41.229778Z","shell.execute_reply.started":"2023-06-29T04:24:38.479938Z","shell.execute_reply":"2023-06-29T04:24:41.228718Z"}}},{"cell_type":"markdown","source":"1. The **age category that generates the highest likelihood value** for a given image is taken to be the **predicted age category** for that image. The predicted age category labels can then be stored as a pandas series named 'Class'","metadata":{}},{"cell_type":"code","source":"tta_arr = first(zip(*tta_preds))\navg_preds = torch.stack(tta_arr).mean(0)\nclass_idx = avg_preds.argmax(dim=1)\n\nimg_dls = ImageDataLoaders.from_folder(trn_images_path,valid_pct=0.25,item_tfms = Resize(64,method='squish'),\n                                           batch_tfms = aug_transforms(size=64,min_scale=0.75),bs=1024)\nlearner_proxy = vision_learner(img_dls,'resnet26d',metrics=error_rate).to_fp16()\nvocab = np.array(learner_proxy.dls.vocab)\n\nresults = pd.Series(vocab[class_idx],name='Class')","metadata":{"execution":{"iopub.status.busy":"2023-07-09T13:26:21.542476Z","iopub.execute_input":"2023-07-09T13:26:21.544778Z","iopub.status.idle":"2023-07-09T13:26:23.792307Z","shell.execute_reply.started":"2023-07-09T13:26:21.544742Z","shell.execute_reply":"2023-07-09T13:26:23.791206Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"2. The age predictions can then be joined with the test dataset to ensure that the predicted age category is aligned correctly actual age category for each test image. With this piece of information, the accuracy of the model can be determined","metadata":{}},{"cell_type":"code","source":"test_image_fl = os.listdir(test_path)\ntest_image = pd.Series(test_image_fl,name='ID')\nout_results = pd.concat([test_image,results],axis=1)\nout = pd.merge(X_test,out_results,how='left',left_on='ID',right_on='ID')\nout.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-09T13:26:23.797212Z","iopub.execute_input":"2023-07-09T13:26:23.799524Z","iopub.status.idle":"2023-07-09T13:26:23.861983Z","shell.execute_reply.started":"2023-07-09T13:26:23.799488Z","shell.execute_reply":"2023-07-09T13:26:23.861126Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"          ID   Class\n0  10654.jpg  MIDDLE\n1  14359.jpg  MIDDLE\n2  14759.jpg   YOUNG\n3  25471.jpg  MIDDLE\n4   6443.jpg  MIDDLE","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10654.jpg</td>\n      <td>MIDDLE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14359.jpg</td>\n      <td>MIDDLE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>14759.jpg</td>\n      <td>YOUNG</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>25471.jpg</td>\n      <td>MIDDLE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6443.jpg</td>\n      <td>MIDDLE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"Class = out['Class']\nprint(f'Accuracy of the model is:{accuracy_score(y_test,Class)}')","metadata":{"execution":{"iopub.status.busy":"2023-07-09T13:26:23.866095Z","iopub.execute_input":"2023-07-09T13:26:23.868351Z","iopub.status.idle":"2023-07-09T13:26:23.891446Z","shell.execute_reply.started":"2023-07-09T13:26:23.868316Z","shell.execute_reply":"2023-07-09T13:26:23.890587Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Accuracy of the model is:0.9007434197307616\n","output_type":"stream"}]},{"cell_type":"markdown","source":"An accuracy of ~90% is possible with the given model configuration. \n\n***The accuracy can be improved further by leveraging architectures with the potential for higher prediction accuracy as outlined in this article.*** The more complicated architectures require higher computing resources for classification","metadata":{}}]}