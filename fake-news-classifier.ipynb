{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8317,"databundleVersionId":109592,"sourceType":"competition"}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-23T09:48:39.926705Z","iopub.execute_input":"2023-12-23T09:48:39.926974Z","iopub.status.idle":"2023-12-23T09:48:40.267568Z","shell.execute_reply.started":"2023-12-23T09:48:39.926949Z","shell.execute_reply":"2023-12-23T09:48:40.266648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers\n!pip install torchmetrics","metadata":{"execution":{"iopub.status.busy":"2023-12-23T09:48:40.269426Z","iopub.execute_input":"2023-12-23T09:48:40.269959Z","iopub.status.idle":"2023-12-23T09:49:06.152906Z","shell.execute_reply.started":"2023-12-23T09:48:40.269926Z","shell.execute_reply":"2023-12-23T09:49:06.151988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install Dataset","metadata":{"execution":{"iopub.status.busy":"2023-12-23T09:49:06.154190Z","iopub.execute_input":"2023-12-23T09:49:06.154520Z","iopub.status.idle":"2023-12-23T09:49:21.545376Z","shell.execute_reply.started":"2023-12-23T09:49:06.154493Z","shell.execute_reply":"2023-12-23T09:49:21.544470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom transformers import AutoTokenizer, BertModel, RobertaForSequenceClassification\nfrom tqdm import tqdm\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom torchmetrics import Accuracy\nfrom datasets import Dataset\nimport datasets\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2023-12-23T09:49:21.548573Z","iopub.execute_input":"2023-12-23T09:49:21.549004Z","iopub.status.idle":"2023-12-23T09:49:33.072221Z","shell.execute_reply.started":"2023-12-23T09:49:21.548965Z","shell.execute_reply":"2023-12-23T09:49:33.071413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/fake-news/train.csv')\n\n#Handle any missing values by filling placeholders\ndata['author'] = data['author'].fillna('Unknown',axis=0)\ndata['title'] = data['title'].fillna('Unknown',axis=0)\ndata['text'] = data['text'].fillna('Not Available',axis=0)\n\n#Create a complete article writeup by concatenating title and author\ndata['comb_news'] = 'Title:'+data['title']+'\\nAuthor:'+data['author']+'\\nBody:'+data['text']\n\n#Extract only the relevant columns from input data\ndata_in = data[['comb_news','label']]","metadata":{"execution":{"iopub.status.busy":"2023-12-23T09:49:33.073276Z","iopub.execute_input":"2023-12-23T09:49:33.073706Z","iopub.status.idle":"2023-12-23T09:49:36.049325Z","shell.execute_reply.started":"2023-12-23T09:49:33.073680Z","shell.execute_reply":"2023-12-23T09:49:36.048542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Define the tokenizer and the function used to tokenize the data\nmodel_name = 'roberta-base'\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\ndef tokenize(el):\n    result =  tokenizer(el['comb_news'],truncation=True,max_length=128,padding='max_length',return_overflowing_tokens=True)\n    sample_map = result.pop('overflow_to_sample_mapping')\n    for key,value in el.items():\n        result[key] = [value[i] for i in sample_map]\n        \n    return result","metadata":{"execution":{"iopub.status.busy":"2023-12-23T09:49:36.050597Z","iopub.execute_input":"2023-12-23T09:49:36.051382Z","iopub.status.idle":"2023-12-23T09:49:37.346156Z","shell.execute_reply.started":"2023-12-23T09:49:36.051342Z","shell.execute_reply":"2023-12-23T09:49:37.345438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function used to tokenize the data and create data loaders\ndef create_loaders(data_in):\n    #Split relevant columns into training and validation datasets \n    train_data, test_data, train_label, test_label = train_test_split(data_in['comb_news'],data_in['label'],test_size=0.25,random_state=42)\n    \n    data_train = Dataset.from_pandas(pd.concat([train_data,train_label],axis=1))\n    data_valid = Dataset.from_pandas(pd.concat([test_data,test_label],axis=1))\n    \n    tr_data = datasets.DatasetDict({'train':data_train,'valid':data_valid})\n    \n    tok_data = tr_data.map(tokenize,batched=True)\n    tok_data = tok_data.remove_columns(['comb_news','__index_level_0__'])\n    tok_data.set_format('pandas')\n    \n    train_in = tok_data['train'][:]\n    train_set = TensorDataset(torch.tensor(train_in['input_ids']),torch.tensor(train_in['attention_mask']),torch.tensor(train_in['label']))\n    \n    valid_in = tok_data['valid'][:]\n    valid_set = TensorDataset(torch.tensor(valid_in['input_ids']),torch.tensor(valid_in['attention_mask']),torch.tensor(valid_in['label']))\n    \n    #Define data loaders for both the training and validation data sets\n    train_loader = DataLoader(train_set,batch_size=64,shuffle=True)\n    valid_loader = DataLoader(valid_set,batch_size=64,shuffle=False)\n    \n    return train_loader,valid_loader","metadata":{"execution":{"iopub.status.busy":"2023-12-23T09:49:37.347191Z","iopub.execute_input":"2023-12-23T09:49:37.347454Z","iopub.status.idle":"2023-12-23T09:49:37.357052Z","shell.execute_reply.started":"2023-12-23T09:49:37.347432Z","shell.execute_reply":"2023-12-23T09:49:37.356216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader,valid_loader = create_loaders(data_in)\nvalid_loader","metadata":{"execution":{"iopub.status.busy":"2023-12-23T09:49:37.358330Z","iopub.execute_input":"2023-12-23T09:49:37.358651Z","iopub.status.idle":"2023-12-23T09:50:54.394721Z","shell.execute_reply.started":"2023-12-23T09:49:37.358621Z","shell.execute_reply":"2023-12-23T09:50:54.393689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Define the model\nmodel = RobertaForSequenceClassification.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T09:50:54.395823Z","iopub.execute_input":"2023-12-23T09:50:54.396111Z","iopub.status.idle":"2023-12-23T09:50:57.555903Z","shell.execute_reply.started":"2023-12-23T09:50:54.396086Z","shell.execute_reply":"2023-12-23T09:50:57.555164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = model.to(device)\nfor idx,(name,params) in enumerate(model.named_parameters()):\n    if 'classifier' in name or 'encoder.layer.8' in name or 'encoder.layer.9' in name or 'encoder.layer.10' in name:\n        params.requires_grad = True\n    else:\n        params.requires_grad = False\n        \ntotal_params = 0\nfor param in model.parameters():\n    if param.requires_grad:\n        total_params+= param.numel()\nprint(total_params)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T09:50:57.559300Z","iopub.execute_input":"2023-12-23T09:50:57.559704Z","iopub.status.idle":"2023-12-23T09:51:02.434041Z","shell.execute_reply.started":"2023-12-23T09:50:57.559666Z","shell.execute_reply":"2023-12-23T09:51:02.433069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs=2\noptimizer = torch.optim.AdamW(model.parameters(),lr=5e-5,eps=1e-8)\ncriterion = torch.nn.CrossEntropyLoss()\ntrain_acc,valid_acc = Accuracy(task='binary',num_classes=2).to(device),Accuracy(task='binary',num_classes=2).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T09:51:02.435034Z","iopub.execute_input":"2023-12-23T09:51:02.435307Z","iopub.status.idle":"2023-12-23T09:51:02.445072Z","shell.execute_reply.started":"2023-12-23T09:51:02.435284Z","shell.execute_reply":"2023-12-23T09:51:02.444254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(epochs):\n    train_loss, valid_loss = list(),list()\n    print(f'Epoch:{epoch}----------------------->')\n    \n    model.train()\n    for idx,(x_ids,x_mask,x_label) in tqdm(enumerate(train_loader),total=len(train_loader)):\n        optimizer.zero_grad()\n        x_ids, x_mask, x_label = x_ids.to(device), x_mask.to(device), x_label.to(device)\n        preds = model(x_ids,attention_mask = x_mask)\n        loss = criterion(preds.logits,x_label)\n        train_loss.append(loss.item())\n        train_acc.update(torch.argmax(preds.logits,dim=1),x_label)\n        torch.nn.utils.clip_grad_norm_(model.parameters(),1.0)\n        loss.backward()\n        optimizer.step()\n        \n    model.eval()\n    for idx,(v_ids,v_mask,v_label) in tqdm(enumerate(valid_loader),total=len(valid_loader)):\n        v_ids, v_mask, v_label = v_ids.to(device), v_mask.to(device), v_label.to(device)\n        preds = model(v_ids,attention_mask = v_mask)\n        loss = criterion(preds.logits,v_label)\n        valid_loss.append(loss.item())\n        valid_acc.update(torch.argmax(preds.logits,dim=1),v_label)\n        \n    avg_train_loss, avg_valid_loss = sum(train_loss)/len(train_loss),sum(valid_loss)/len(valid_loss)\n    print(f'Training loss:{avg_train_loss}\\tValidation loss:{avg_valid_loss}')\n    print(f'Training accuracy:{train_acc.compute().item()}\\tValidation accuracy:{valid_acc.compute().item()}')","metadata":{"execution":{"iopub.status.busy":"2023-12-23T09:51:02.446094Z","iopub.execute_input":"2023-12-23T09:51:02.446371Z","iopub.status.idle":"2023-12-23T11:17:58.587130Z","shell.execute_reply.started":"2023-12-23T09:51:02.446347Z","shell.execute_reply":"2023-12-23T11:17:58.586231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def flatten_data(data):\n    flat_list = list()\n    for item in data:\n        flat_list += item.tolist()\n    return flat_list\n\ndef find_issue(d_out):\n    check_issue = pd.crosstab(d_out['id'],d_out['label']).reset_index().rename(columns={'id':'index',0:'label_0',1:'label_1'})\n    check_issue['issue_flag'] = check_issue.apply(lambda x: x['label_0']>0 & x['label_1']>0,axis=1)\n    errors = check_issue.shape[0]-check_issue['issue_flag'].value_counts().to_frame().reset_index().loc[0,'count']\n    return errors","metadata":{"execution":{"iopub.status.busy":"2023-12-23T12:49:58.473025Z","iopub.execute_input":"2023-12-23T12:49:58.474103Z","iopub.status.idle":"2023-12-23T12:49:58.480547Z","shell.execute_reply.started":"2023-12-23T12:49:58.474063Z","shell.execute_reply":"2023-12-23T12:49:58.479718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Assess model performance on the test data\nd_test = pd.read_csv('/kaggle/input/fake-news/test.csv')\n\ndef generate_result(test):\n    #Handle any missing values by filling placeholders\n    test['author'] = test['author'].fillna('Unknown',axis=0)\n    test['title'] = test['title'].fillna('Unknown',axis=0)\n    test['text'] = test['text'].fillna('Not Available',axis=0)\n    \n    #Concatenating title and author with text body to prevent loss of important data\n    test['comb_news'] = 'Title:'+test['title']+'\\nAuthor:'+test['author']+'\\nBody:'+test['text']\n    d_test_in = d_test[['id','comb_news']]\n    \n    test_dset = Dataset.from_pandas(d_test_in)\n    #Tokenize the test data with the Roberta tokenizer\n    test_tokens = test_dset.map(tokenize,batched=True)\n    test_tokens = test_tokens.remove_columns(['comb_news'])\n    test_tokens.set_format('pandas')\n\n    torch_t_data = TensorDataset(torch.tensor(test_tokens['input_ids']),torch.tensor(test_tokens['attention_mask']))\n    test_dataloader = DataLoader(torch_t_data,batch_size=64,shuffle=False)\n    label_preds = list()\n    \n    #Determine the predictions from the model\n    model.eval()\n    for idx,(t_inputs,t_amask) in tqdm(enumerate(test_dataloader),total=len(test_dataloader)):\n        t_inputs,t_amask = t_inputs.to(device),t_amask.to(device)\n        preds = model(t_inputs,attention_mask = t_amask)\n        p_label = torch.argmax(preds.logits,dim=1)\n        label_preds.append(p_label)\n    \n    test_predictions = flatten_data(label_preds)\n    output = pd.concat([test_tokens['id'],pd.DataFrame(test_predictions,columns=['label'])],axis='columns')\n    \n    if find_issue(output)==0:\n        return output.drop_duplicates(subset=['id'])\n    else:\n        return -1","metadata":{"execution":{"iopub.status.busy":"2023-12-23T12:53:57.039289Z","iopub.execute_input":"2023-12-23T12:53:57.040061Z","iopub.status.idle":"2023-12-23T12:53:57.350042Z","shell.execute_reply.started":"2023-12-23T12:53:57.040028Z","shell.execute_reply":"2023-12-23T12:53:57.349071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f_output = generate_result(d_test)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T12:54:02.936715Z","iopub.execute_input":"2023-12-23T12:54:02.937346Z","iopub.status.idle":"2023-12-23T12:59:33.724269Z","shell.execute_reply.started":"2023-12-23T12:54:02.937315Z","shell.execute_reply":"2023-12-23T12:59:33.723468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f_output.to_csv('submit.csv',index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-23T13:01:58.103902Z","iopub.execute_input":"2023-12-23T13:01:58.104258Z","iopub.status.idle":"2023-12-23T13:01:58.120828Z","shell.execute_reply.started":"2023-12-23T13:01:58.104229Z","shell.execute_reply":"2023-12-23T13:01:58.120047Z"},"trusted":true},"execution_count":null,"outputs":[]}]}