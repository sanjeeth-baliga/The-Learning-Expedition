{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction","metadata":{}},{"cell_type":"markdown","source":"The code that follows leverages language transformer models to perform a sequence of two tasks that enables the generation of a short story script in the english language\n1. **Semantic search** through a transformer fine-tuned to the sentence classification problem to extract a set of words from a corpus of philosophical quotes\n2. **Text generation** by fine tuning a transformer model to the sentence completion problem by leveraging the words generated from the earlier stage to start a new sentence\n\nThe huggingface model hub has been used to load the required datasets and fine-tune the transformer models for accomplishing the task described above. I would advise you to take a course offered by huggingfaces linked [here](https://huggingface.co/learn/nlp-course/chapter0/1?fw=pt) if you are interested in exploring this further or checking out other language models","metadata":{}},{"cell_type":"markdown","source":"This code has been built and tested in the kaggle ecosystem. Hence, if a similar notebook environment is utilized by a user, it is advisable to make all installations associated with libraries involving the huggingface models","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n!pip install datasets\n!pip install -U git+https://github.com/huggingface/transformers.git\n!pip install -U git+https://github.com/huggingface/accelerate.git\n!pip install faiss-cpu","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-04T17:54:09.905531Z","iopub.execute_input":"2023-07-04T17:54:09.906154Z","iopub.status.idle":"2023-07-04T17:54:09.931095Z","shell.execute_reply.started":"2023-07-04T17:54:09.906121Z","shell.execute_reply":"2023-07-04T17:54:09.930089Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/inputs/tiny-book-corpus-validation.jsonl\n/kaggle/input/inputs/tiny-book-corpus-train.jsonl\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Sentence Completion using a Text generation transformer model","metadata":{}},{"cell_type":"markdown","source":"The second section of the problem will be tackled first to build a huggingfaces pipeline that is capable of generating a short story script when provided with one or more sentence starters","metadata":{}},{"cell_type":"markdown","source":"1. The bookcorpus dataset available on the huggingface model hub can be used to fine tune a GPT-based text generation model for making it suitable to the task of story script generation. However, the dataset is too large in a resource crunched environment to train within a reasonable amount of time. So for the purpose of this modeling exercise, around 60,000 samples are extracted from the entire dataset and used for fine tuning purpose. The following code which is commented out serves to extract the 60,000 random text samples. This could be uncommented and run only once when the notebook is executed for the first time. After the first run, the condensed dataset of 60,000 samples will be stored due to which we can again comment out the code section for the subsequent runs. In this step, the training dataset of 60,000 samples can be further split into training and validation sets by selecting a suitable split ratio","metadata":{}},{"cell_type":"code","source":"#from datasets import load_dataset\n#import datasets\n#raw_story_scripts_train = load_dataset('bookcorpus',split='train[:20%]+train[-20%:]')\n#condensed_size = 60000\n#raw_story_scripts={'train':raw_story_scripts_train}\n#raw_story_scripts = datasets.DatasetDict(raw_story_scripts)\n#raw_story_scripts_condensed = raw_story_scripts['train'].shuffle(seed=42).select(range(condensed_size))\n#split_dataset = raw_story_scripts_condensed.train_test_split(test_size=0.2,seed=42)\n#split_dataset['validation'] = split_dataset.pop('test')\n#for split,dataset in split_dataset.items():\n#    dataset.to_json(f'tiny-book-corpus-{split}.jsonl')","metadata":{"execution":{"iopub.status.busy":"2023-07-04T10:52:20.998548Z","iopub.execute_input":"2023-07-04T10:52:20.999982Z","iopub.status.idle":"2023-07-04T11:18:41.349512Z","shell.execute_reply.started":"2023-07-04T10:52:20.999927Z","shell.execute_reply":"2023-07-04T11:18:41.347316Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset bookcorpus/plain_text (download: 1.10 GiB, generated: 4.52 GiB, post-processed: Unknown size, total: 5.62 GiB) to /root/.cache/huggingface/datasets/bookcorpus/plain_text/1.0.0/44662c4a114441c35200992bea923b170e6f13f2f0beb7c14e43759cec498700...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/74004228 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset bookcorpus downloaded and prepared to /root/.cache/huggingface/datasets/bookcorpus/plain_text/1.0.0/44662c4a114441c35200992bea923b170e6f13f2f0beb7c14e43759cec498700. Subsequent calls will reuse this data.\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text'],\n    num_rows: 29601692\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"2. The stored 60,000 samples can be loaded by providing the path of the local directory where the samples are stored. It should be ensured that the path string **/kaggle/input/inputs/** is replaced by the correct local directory path","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\ndata_files = {'train':'/kaggle/input/inputs/tiny-book-corpus-train.jsonl','test':'/kaggle/input/inputs/tiny-book-corpus-validation.jsonl'}\nsplit_dataset = load_dataset('json',data_files=data_files)\nsplit_dataset['validation'] = split_dataset.pop('test')","metadata":{"execution":{"iopub.status.busy":"2023-07-04T18:12:01.291105Z","iopub.execute_input":"2023-07-04T18:12:01.291511Z","iopub.status.idle":"2023-07-04T18:12:01.872702Z","shell.execute_reply.started":"2023-07-04T18:12:01.291476Z","shell.execute_reply":"2023-07-04T18:12:01.871722Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-47c4e9a206c111e4/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad03b063b99a42f3badce84e46750644"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7ec29db10114845be3286c2c7cd852d"}},"metadata":{}},{"name":"stdout","text":"Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-47c4e9a206c111e4/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57fa10596a334cbfa8200af759884350"}},"metadata":{}}]},{"cell_type":"code","source":"split_dataset","metadata":{"execution":{"iopub.status.busy":"2023-07-04T18:12:07.376069Z","iopub.execute_input":"2023-07-04T18:12:07.376464Z","iopub.status.idle":"2023-07-04T18:12:07.382607Z","shell.execute_reply.started":"2023-07-04T18:12:07.376431Z","shell.execute_reply":"2023-07-04T18:12:07.381592Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text'],\n        num_rows: 48000\n    })\n    validation: Dataset({\n        features: ['text'],\n        num_rows: 12000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, GPT2LMHeadModel\nmodel_checkpoint = 'distilgpt2'\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\nmodel = GPT2LMHeadModel.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2023-07-04T18:12:12.565571Z","iopub.execute_input":"2023-07-04T18:12:12.565930Z","iopub.status.idle":"2023-07-04T18:12:17.875601Z","shell.execute_reply.started":"2023-07-04T18:12:12.565901Z","shell.execute_reply":"2023-07-04T18:12:17.874558Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cba82889baae435daa3f3ff9593faad8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb2ea6dce3c240cfafcaa43d8c820b9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3197a3bd5c5043f09baf2fa6a36481fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc1681557b644f75ae6100d3e35d4c29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18fe7903bbbe4c09ae7c063804c31a06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"844ce05fdf6b4e5f9a0fdc013abb80a6"}},"metadata":{}}]},{"cell_type":"code","source":"def count_str_length(el):\n    return {'word_length':[len(sample.split(' ')) for sample in el['text']]}","metadata":{"execution":{"iopub.status.busy":"2023-07-04T17:56:27.535118Z","iopub.execute_input":"2023-07-04T17:56:27.535489Z","iopub.status.idle":"2023-07-04T17:56:27.540934Z","shell.execute_reply.started":"2023-07-04T17:56:27.535458Z","shell.execute_reply":"2023-07-04T17:56:27.539565Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\nsplit_dataset = split_dataset.map(count_str_length,batched=True)\nsplit_dataset.set_format('pandas')","metadata":{"execution":{"iopub.status.busy":"2023-07-04T18:12:26.375923Z","iopub.execute_input":"2023-07-04T18:12:26.376297Z","iopub.status.idle":"2023-07-04T18:12:26.636637Z","shell.execute_reply.started":"2023-07-04T18:12:26.376268Z","shell.execute_reply":"2023-07-04T18:12:26.635711Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/48 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e0a3e35289a4560b2154a6bfc348027"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18b3b983bfe644baba427805499aebe9"}},"metadata":{}}]},{"cell_type":"code","source":"split_dataset.reset_format()\nsplit_dataset = split_dataset.filter(lambda x: x['word_length']>=15)\nsplit_dataset","metadata":{"execution":{"iopub.status.busy":"2023-07-04T18:12:31.225755Z","iopub.execute_input":"2023-07-04T18:12:31.226114Z","iopub.status.idle":"2023-07-04T18:12:31.659220Z","shell.execute_reply.started":"2023-07-04T18:12:31.226086Z","shell.execute_reply":"2023-07-04T18:12:31.658354Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/48 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29c958bfe5534e21a62ec7f2f288c19a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c90e100a2154d38b307430b93265261"}},"metadata":{}},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'word_length'],\n        num_rows: 16994\n    })\n    validation: Dataset({\n        features: ['text', 'word_length'],\n        num_rows: 4275\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"context_length=512\ndef tokenize_scripts(el):\n    tok_output = tokenizer(el['text'], truncation=True, max_length=context_length,\n                    return_overflowing_tokens=True,return_length=True)\n    return {'input_ids':tok_output['input_ids']}","metadata":{"execution":{"iopub.status.busy":"2023-07-04T18:12:52.813808Z","iopub.execute_input":"2023-07-04T18:12:52.814159Z","iopub.status.idle":"2023-07-04T18:12:52.820921Z","shell.execute_reply.started":"2023-07-04T18:12:52.814130Z","shell.execute_reply":"2023-07-04T18:12:52.818576Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"tokenized_dataset = split_dataset.map(tokenize_scripts,batched=True,\n                                      remove_columns=split_dataset['train'].column_names)\ntokenized_dataset","metadata":{"execution":{"iopub.status.busy":"2023-07-04T18:13:03.315489Z","iopub.execute_input":"2023-07-04T18:13:03.315871Z","iopub.status.idle":"2023-07-04T18:13:05.918918Z","shell.execute_reply.started":"2023-07-04T18:13:03.315841Z","shell.execute_reply":"2023-07-04T18:13:05.918007Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/17 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0f4d20ea2ee472faf6b3292f8361402"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ad9b8a1d79b494dbf6a824e5e059d98"}},"metadata":{}},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids'],\n        num_rows: 16994\n    })\n    validation: Dataset({\n        features: ['input_ids'],\n        num_rows: 4275\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorForLanguageModeling\ntokenizer.pad_token = tokenizer.eos_token\ndata_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer,mlm=False)\nout = data_collator([tokenized_dataset['train'][i] for i in range(3)])\nfor key in out:\n    print(f'{key} shape:{out[key].shape}')","metadata":{"execution":{"iopub.status.busy":"2023-07-04T18:13:21.912276Z","iopub.execute_input":"2023-07-04T18:13:21.912658Z","iopub.status.idle":"2023-07-04T18:13:22.459568Z","shell.execute_reply.started":"2023-07-04T18:13:21.912629Z","shell.execute_reply":"2023-07-04T18:13:22.458409Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"name":"stdout","text":"input_ids shape:torch.Size([3, 46])\nattention_mask shape:torch.Size([3, 46])\nlabels shape:torch.Size([3, 46])\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2023-07-04T18:14:04.047054Z","iopub.execute_input":"2023-07-04T18:14:04.047474Z","iopub.status.idle":"2023-07-04T18:14:04.097285Z","shell.execute_reply.started":"2023-07-04T18:14:04.047440Z","shell.execute_reply":"2023-07-04T18:14:04.096399Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8faa60eea81d49ba9e9feb4f8c7cf131"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\nargs = TrainingArguments(\n    f'tiny-random-GPT2LMHeadModel-finetuned-corpus',\n    overwrite_output_dir=True,\n    num_train_epochs=3,\n    evaluation_strategy='epoch',\n    save_strategy='epoch',\n    learning_rate=5e-4,\n    weight_decay = 0.01,\n    fp16=True,\n    push_to_hub=True\n)\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset = tokenized_dataset['train'],\n    eval_dataset = tokenized_dataset['validation'],\n    tokenizer = tokenizer,\n    data_collator = data_collator\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-04T18:14:35.398924Z","iopub.execute_input":"2023-07-04T18:14:35.399300Z","iopub.status.idle":"2023-07-04T18:16:35.540675Z","shell.execute_reply.started":"2023-07-04T18:14:35.399268Z","shell.execute_reply":"2023-07-04T18:16:35.539584Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"Cloning https://huggingface.co/san94/tiny-random-GPT2LMHeadModel-finetuned-corpus into local empty directory.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Download file pytorch_model.bin:   0%|          | 15.4k/312M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e186bed3ccd64d599623e3a3697f3e71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Download file training_args.bin: 100%|##########| 3.93k/3.93k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40b7ef8ddb524b49856ef35dc946d5e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Download file runs/Jul04_12-41-46_20b74ae67198/events.out.tfevents.1688474526.20b74ae67198.28.0: 100%|########…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89b30816a1564a31a248b72697d57804"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Clean file training_args.bin:  25%|##5       | 1.00k/3.93k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecf19fee92ed4658869f886405b0def1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Clean file runs/Jul04_12-41-46_20b74ae67198/events.out.tfevents.1688474526.20b74ae67198.28.0:  16%|#5        |…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d0c6b7251d04b07a9f5eb46dba08941"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Clean file pytorch_model.bin:   0%|          | 1.00k/312M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"850c3a8dfe6f4ef2a7c4dd0b5cbbe6d6"}},"metadata":{}}]},{"cell_type":"code","source":"trainer.train()\ntrainer.push_to_hub()","metadata":{"execution":{"iopub.status.busy":"2023-07-04T18:16:41.446020Z","iopub.execute_input":"2023-07-04T18:16:41.446436Z","iopub.status.idle":"2023-07-04T18:29:43.457300Z","shell.execute_reply.started":"2023-07-04T18:16:41.446404Z","shell.execute_reply":"2023-07-04T18:29:43.456233Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230704_181652-el637y8u</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/baligasanjeeth/huggingface/runs/el637y8u' target=\"_blank\">trim-smoke-5</a></strong> to <a href='https://wandb.ai/baligasanjeeth/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/baligasanjeeth/huggingface' target=\"_blank\">https://wandb.ai/baligasanjeeth/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/baligasanjeeth/huggingface/runs/el637y8u' target=\"_blank\">https://wandb.ai/baligasanjeeth/huggingface/runs/el637y8u</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3189' max='3189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3189/3189 12:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>4.443300</td>\n      <td>4.278949</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3.701300</td>\n      <td>4.251234</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>3.041200</td>\n      <td>4.449711</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSeveral commits (2) will be pushed upstream.\nThe progress bars may be unreliable.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Upload file runs/Jul04_18-14-35_8ce4b887e41a/events.out.tfevents.1688494601.8ce4b887e41a.28.0:   0%|          …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99cad0059b2c4d07b479d7d3c63a9d96"}},"metadata":{}},{"name":"stderr","text":"To https://huggingface.co/san94/tiny-random-GPT2LMHeadModel-finetuned-corpus\n   cbc59d0..fe6c3bf  main -> main\n\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"'https://huggingface.co/san94/tiny-random-GPT2LMHeadModel-finetuned-corpus/commit/fe6c3bfcb75852ab6265ecd4c77a373ed552cc36'"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import pipeline\nstory_teller = pipeline('text-generation',model='tiny-random-GPT2LMHeadModel-finetuned-corpus')\nstory_teller('Once upon')","metadata":{"execution":{"iopub.status.busy":"2023-07-04T13:00:08.464788Z","iopub.execute_input":"2023-07-04T13:00:08.465191Z","iopub.status.idle":"2023-07-04T13:00:14.058854Z","shell.execute_reply.started":"2023-07-04T13:00:08.465161Z","shell.execute_reply":"2023-07-04T13:00:14.057835Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\npip install xformers.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1363: UserWarning: Using `max_length`'s default (50) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': \"Once upon a success, your potential has disappeared a century or so before it became necessary for you to find me. '' dante turned to gautier and gion. '' gautier opened his mouth again, and gus nodded. ``\"}]"},"metadata":{}}]},{"cell_type":"code","source":"story_teller('You are')[0]['generated_text']","metadata":{"execution":{"iopub.status.busy":"2023-07-04T13:01:15.946319Z","iopub.execute_input":"2023-07-04T13:01:15.946687Z","iopub.status.idle":"2023-07-04T13:01:17.566728Z","shell.execute_reply.started":"2023-07-04T13:01:15.946657Z","shell.execute_reply":"2023-07-04T13:01:17.560805Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"\"You are the ones who've been through all this, '' i said, and julian took the phone from him and placed it on the front of his head. '' `` please give me a call. '' i stepped back, letting the\""},"metadata":{}}]},{"cell_type":"code","source":"story_teller('Roses are red')[0]['generated_text']","metadata":{"execution":{"iopub.status.busy":"2023-07-04T13:07:21.535054Z","iopub.execute_input":"2023-07-04T13:07:21.536088Z","iopub.status.idle":"2023-07-04T13:07:23.082149Z","shell.execute_reply.started":"2023-07-04T13:07:21.536032Z","shell.execute_reply":"2023-07-04T13:07:23.081127Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"\"Roses are red, blood red, gold, and so forth just as blood is stil not healing. '' `` i don't want any of these things dying people, '' he says, `` but you do need to know that a very\""},"metadata":{}}]},{"cell_type":"code","source":"normal_generator = pipeline('text-generation')\nnormal_generator('Roses are red')[0]['generated_text']","metadata":{"execution":{"iopub.status.busy":"2023-07-04T13:08:33.188693Z","iopub.execute_input":"2023-07-04T13:08:33.189809Z","iopub.status.idle":"2023-07-04T13:08:43.562409Z","shell.execute_reply.started":"2023-07-04T13:08:33.189767Z","shell.execute_reply":"2023-07-04T13:08:43.560335Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21bc3205a4f743029000189d06fc0aa6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e4b09685a094eb3a959c60e4e110079"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b87f6c3dfc443ae96cb22d9af233b1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a74cbbc7d046449c994a758aa43301a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cadb04c9e444af7974e37e11b8a4d80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cac73b49cddf47a5a93733342ee7d859"}},"metadata":{}},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'Roses are red, not green (depending on the color). (Photo: Michael Moore / Los Angeles Public Media)\\n\\nIt was part of the plan of the Los Angeles Police Department to provide a safe nightbed for all law enforcement officers in'"},"metadata":{}}]},{"cell_type":"code","source":"normal_generator('Once upon')[0]['generated_text']","metadata":{"execution":{"iopub.status.busy":"2023-07-04T13:09:13.329164Z","iopub.execute_input":"2023-07-04T13:09:13.330170Z","iopub.status.idle":"2023-07-04T13:09:15.863495Z","shell.execute_reply.started":"2023-07-04T13:09:13.330126Z","shell.execute_reply":"2023-07-04T13:09:15.859233Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"'Once upon a return, he made repeated trips to a car dealership and sold his new Bentley. But one morning in September, 2003, when an acquaintance he knew was working at a dealership in Atlanta, Ga., approached him to meet at his house,'"},"metadata":{}}]},{"cell_type":"code","source":"story_teller('My love')[0]['generated_text']","metadata":{"execution":{"iopub.status.busy":"2023-07-04T13:09:43.303829Z","iopub.execute_input":"2023-07-04T13:09:43.304233Z","iopub.status.idle":"2023-07-04T13:09:44.929463Z","shell.execute_reply.started":"2023-07-04T13:09:43.304200Z","shell.execute_reply":"2023-07-04T13:09:44.925375Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"\"My love for you, i can not accept you being tortured until you wish to see it directly upon your own. '' she cried tears again, still clutching at me for a moment. '' she tried to imagine what her eyes had been forced back into\""},"metadata":{}}]},{"cell_type":"code","source":"#Identifying starter content scripts based on supplied string\nfrom datasets import load_dataset\nraw_quote_dataset = load_dataset('mertbozkurt/quotes_philosophers',encoding=\"latin-1\")\nraw_quote_dataset","metadata":{"execution":{"iopub.status.busy":"2023-07-04T17:56:02.791673Z","iopub.execute_input":"2023-07-04T17:56:02.792055Z","iopub.status.idle":"2023-07-04T17:56:07.355997Z","shell.execute_reply.started":"2023-07-04T17:56:02.792021Z","shell.execute_reply":"2023-07-04T17:56:07.355082Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset text/mertbozkurt--quotes_philosophers to /root/.cache/huggingface/datasets/text/mertbozkurt--quotes_philosophers-da87b9e9f82c0fa9/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"662b4e26561e4d39bc8ac0a43af5bd81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/40.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c00d09a486304f19a7d07df372cd0d98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/66.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e767aa0dd84c47c5be2adb3bcecc1d4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/30.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d89cf126624c4df1aae6fcd3047c7b11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/22.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf97c8cd7a294d5e93360942085a366d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/52.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ba63fc363954dfaa1c5f013b62fd5ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/44.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27a1411438444cae9fcf4dca0b2001ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/7.77k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9357289e61f49098e0e71460d013203"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/64.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5546dea298874c688b4cc3026e3a0797"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/20.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6434b4df04ef47e0b1413827fdabc88f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9aadd130924541c0b8e4f78c6a1ae33b"}},"metadata":{}},{"name":"stdout","text":"Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/mertbozkurt--quotes_philosophers-da87b9e9f82c0fa9/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05756f6923fe41e8a9ee1e74535d9ad2"}},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text'],\n        num_rows: 2458\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"raw_quote_dataset['train'][:3]['text']","metadata":{"execution":{"iopub.status.busy":"2023-07-04T17:10:41.940066Z","iopub.execute_input":"2023-07-04T17:10:41.940919Z","iopub.status.idle":"2023-07-04T17:10:41.948435Z","shell.execute_reply.started":"2023-07-04T17:10:41.940870Z","shell.execute_reply":"2023-07-04T17:10:41.947297Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"[\"Be a free thinker and don't accept everything you hear as truth. Be critical and evaluate what you believe in.\",\n 'Excellence is never an accident. It is always the result of high intention, sincere effort, and intelligent execution; it represents the wise choice of many alternatives - choice, not chance, determines your destiny.',\n 'To appreciate the beauty of a snow flake, it is necessary to stand out in the cold.']"},"metadata":{}}]},{"cell_type":"code","source":"raw_quote_dataset = raw_quote_dataset.map(count_str_length,batched=True)\nraw_quote_dataset.set_format('pandas')","metadata":{"execution":{"iopub.status.busy":"2023-07-04T17:56:33.806841Z","iopub.execute_input":"2023-07-04T17:56:33.807193Z","iopub.status.idle":"2023-07-04T17:56:33.934869Z","shell.execute_reply.started":"2023-07-04T17:56:33.807164Z","shell.execute_reply":"2023-07-04T17:56:33.933819Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"292f568b5d664aa0a350971e9dcc59b2"}},"metadata":{}}]},{"cell_type":"code","source":"len_dist = raw_quote_dataset['train']['word_length'].value_counts().to_frame().reset_index().rename(columns={'index':'word_length','word_length':'len_count'}).sort_values('word_length',ascending=False)\nlen_dist","metadata":{"execution":{"iopub.status.busy":"2023-07-04T17:56:38.985412Z","iopub.execute_input":"2023-07-04T17:56:38.985764Z","iopub.status.idle":"2023-07-04T17:56:39.036077Z","shell.execute_reply.started":"2023-07-04T17:56:38.985735Z","shell.execute_reply":"2023-07-04T17:56:39.034874Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"     word_length  len_count\n99           109          1\n102          108          1\n94           107          2\n96           106          1\n89           105          2\n..           ...        ...\n13             6         64\n22             5         36\n33             4         23\n54             3          8\n104            1          1\n\n[105 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word_length</th>\n      <th>len_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>99</th>\n      <td>109</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>108</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>107</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>106</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>105</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>6</td>\n      <td>64</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>5</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>4</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>3</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>104</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>105 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sum(len_dist['len_count'])","metadata":{"execution":{"iopub.status.busy":"2023-07-04T17:23:07.331303Z","iopub.execute_input":"2023-07-04T17:23:07.331685Z","iopub.status.idle":"2023-07-04T17:23:07.337299Z","shell.execute_reply.started":"2023-07-04T17:23:07.331655Z","shell.execute_reply":"2023-07-04T17:23:07.336588Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"2458"},"metadata":{}}]},{"cell_type":"code","source":"sum(len_dist[(len_dist.word_length<50) & (len_dist.word_length>=5)]['len_count'])","metadata":{"execution":{"iopub.status.busy":"2023-07-04T17:56:46.892546Z","iopub.execute_input":"2023-07-04T17:56:46.893126Z","iopub.status.idle":"2023-07-04T17:56:46.901663Z","shell.execute_reply.started":"2023-07-04T17:56:46.893089Z","shell.execute_reply":"2023-07-04T17:56:46.900483Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"2143"},"metadata":{}}]},{"cell_type":"code","source":"raw_quote_dataset.reset_format()\nraw_quote_dataset = raw_quote_dataset.filter(lambda x: (x['word_length']<=50)&(x['word_length']>=5))\nraw_quote_dataset","metadata":{"execution":{"iopub.status.busy":"2023-07-04T17:56:51.995589Z","iopub.execute_input":"2023-07-04T17:56:51.995967Z","iopub.status.idle":"2023-07-04T17:56:52.054465Z","shell.execute_reply.started":"2023-07-04T17:56:51.995925Z","shell.execute_reply":"2023-07-04T17:56:52.053537Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84992e0126994334854d77a814c261d2"}},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'word_length'],\n        num_rows: 2160\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel\nimport torch\nss_checkpoint = 'sentence-transformers/multi-qa-mpnet-base-dot-v1'\nss_tokenizer = AutoTokenizer.from_pretrained(ss_checkpoint)\nss_model = AutoModel.from_pretrained(ss_checkpoint)\n\ndevice = torch.device('cuda') if torch.device('cuda') is not None else torch.device('cpu')\nss_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-07-04T17:56:56.614686Z","iopub.execute_input":"2023-07-04T17:56:56.615034Z","iopub.status.idle":"2023-07-04T17:57:34.733632Z","shell.execute_reply.started":"2023-07-04T17:56:56.615007Z","shell.execute_reply":"2023-07-04T17:57:34.732385Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7af4227abc14c50b503159d443ce0dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49288892f30a4c1cbb5662079084b42c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5131f9c46e5461aa07a4eb195afecac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de65b3a6964c4bd1a7bea50725ca7757"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"818a21241d414d73b110b5643f97b1f3"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3efda629751447e28ead352ba843656b"}},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"MPNetModel(\n  (embeddings): MPNetEmbeddings(\n    (word_embeddings): Embedding(30527, 768, padding_idx=1)\n    (position_embeddings): Embedding(514, 768, padding_idx=1)\n    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): MPNetEncoder(\n    (layer): ModuleList(\n      (0-11): 12 x MPNetLayer(\n        (attention): MPNetAttention(\n          (attn): MPNetSelfAttention(\n            (q): Linear(in_features=768, out_features=768, bias=True)\n            (k): Linear(in_features=768, out_features=768, bias=True)\n            (v): Linear(in_features=768, out_features=768, bias=True)\n            (o): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (intermediate): MPNetIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): MPNetOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (relative_attention_bias): Embedding(32, 12)\n  )\n  (pooler): MPNetPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (activation): Tanh()\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"def cls_pooling(model_out):\n    return model_out.last_hidden_state[:,0]\n\ndef generate_embeddings(el):\n    tkzd_inputs = ss_tokenizer(el,padding=True,return_tensors='pt')\n    tkzd_inputs = {k:v.to(device) for k,v in tkzd_inputs.items()}\n    outputs = ss_model(**tkzd_inputs)\n    return cls_pooling(outputs)","metadata":{"execution":{"iopub.status.busy":"2023-07-04T18:09:38.531913Z","iopub.execute_input":"2023-07-04T18:09:38.532299Z","iopub.status.idle":"2023-07-04T18:09:38.540748Z","shell.execute_reply.started":"2023-07-04T18:09:38.532268Z","shell.execute_reply":"2023-07-04T18:09:38.539588Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"raw_quote_dataset = raw_quote_dataset['train']\nembedding_space = raw_quote_dataset.map(lambda x:{'embedding':generate_embeddings(x['text']).detach().cpu().numpy()[0]})\nembedding_space.add_faiss_index(column='embedding')","metadata":{"execution":{"iopub.status.busy":"2023-07-04T18:09:45.216038Z","iopub.execute_input":"2023-07-04T18:09:45.216404Z","iopub.status.idle":"2023-07-04T18:10:18.213438Z","shell.execute_reply.started":"2023-07-04T18:09:45.216374Z","shell.execute_reply":"2023-07-04T18:10:18.212252Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2160 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"444f4eeeb84d4abbbccc0a698b61bff1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73b666a308d94507b5ea73deecb401bd"}},"metadata":{}},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text', 'word_length', 'embedding'],\n    num_rows: 2160\n})"},"metadata":{}}]},{"cell_type":"code","source":"def semantic_search(question):\n    question_embedding = generate_embeddings([question]).detach().cpu().numpy()[0]\n    scores,samples = embedding_space.get_nearest_examples('embedding',question_embedding,k=5)\n    sample_df = pd.DataFrame.from_dict(samples)\n    sample_df['scores'] = scores\n    sample_df.sort_values('scores',ascending=False,inplace=True)\n    return sample_df","metadata":{"execution":{"iopub.status.busy":"2023-07-04T18:11:12.592123Z","iopub.execute_input":"2023-07-04T18:11:12.592509Z","iopub.status.idle":"2023-07-04T18:11:12.598928Z","shell.execute_reply.started":"2023-07-04T18:11:12.592480Z","shell.execute_reply":"2023-07-04T18:11:12.597901Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"story_starters = []\nsearch_results = semantic_search('what is life?')\nfor _,row in search_results.iterrows():\n    story_starters.append(row.text)\nstory_starters","metadata":{"execution":{"iopub.status.busy":"2023-07-04T19:15:06.706908Z","iopub.execute_input":"2023-07-04T19:15:06.707297Z","iopub.status.idle":"2023-07-04T19:15:06.749442Z","shell.execute_reply.started":"2023-07-04T19:15:06.707267Z","shell.execute_reply":"2023-07-04T19:15:06.748379Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"['Life is nothing until it is lived; but it is yours to make sense of, and the of it is nothing other than the sense you choose.',\n 'Life is the faculty of spontaneous activity, the awareness that we have powers.',\n 'Life is the will to power; our natural desire to dominate and reshape the world to fit our own preferences and assert our personal strength to the fullest degree.',\n 'Life in the true sense is perceiving or thinking.',\n 'Life is a constant process of dying.']"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import pipeline\nstory_teller = pipeline('text-generation',model='tiny-random-GPT2LMHeadModel-finetuned-corpus')\nstory_teller(story_starters)","metadata":{"execution":{"iopub.status.busy":"2023-07-04T19:15:26.489273Z","iopub.execute_input":"2023-07-04T19:15:26.490245Z","iopub.status.idle":"2023-07-04T19:15:33.432829Z","shell.execute_reply.started":"2023-07-04T19:15:26.490210Z","shell.execute_reply":"2023-07-04T19:15:33.431696Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1363: UserWarning: Using `max_length`'s default (50) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"[[{'generated_text': \"Life is nothing until it is lived; but it is yours to make sense of, and the of it is nothing other than the sense you choose. '' `` look at me, she says. '' mrs. durnik, the words one\"}],\n [{'generated_text': \"Life is the faculty of spontaneous activity, the awareness that we have powers. '' `` think about this. '' he sighed. `` i am sure you understand. '' he repeated the words. '' he began to repeat himself again. '' a hand on\"}],\n [{'generated_text': \"Life is the will to power; our natural desire to dominate and reshape the world to fit our own preferences and assert our personal strength to the fullest degree.'''''''''''''''she continued.\"}],\n [{'generated_text': \"Life in the true sense is perceiving or thinking. less worrying because someone is spending their time in temporary flevance.'' '' '' i'm not going to waste a second too long, so i go back to sleep.'m\"}],\n [{'generated_text': \"Life is a constant process of dying.'''''''''-she's been dead for about six or seven years-'''''''' -i asked her as we swiped her hands in front\"}]]"},"metadata":{}}]}]}