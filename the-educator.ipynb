{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8308438,"sourceType":"datasetVersion","datasetId":4935173},{"sourceId":8308505,"sourceType":"datasetVersion","datasetId":4935219}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-14T18:37:53.856635Z","iopub.execute_input":"2024-05-14T18:37:53.857049Z","iopub.status.idle":"2024-05-14T18:37:54.355620Z","shell.execute_reply.started":"2024-05-14T18:37:53.857018Z","shell.execute_reply":"2024-05-14T18:37:54.354454Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/pdf-example/attention-is-all-you-need.pdf\n/kaggle/input/example-files/The Economic Case for Generative AI.html\n/kaggle/input/example-files/Generative AI_ The Next Consumer Platform _ Andreessen Horowitz.html\n/kaggle/input/example-files/The Future of Prosumer_ The Rise of AI Workflows .html\n","output_type":"stream"}]},{"cell_type":"code","source":"# Warning control\nimport warnings\nwarnings.filterwarnings('ignore')\n\n!pip install --quiet unstructured\n!pip install --quiet chromadb\n!apt-get install poppler-utils -y\n!pip install --quiet --upgrade unstructured[local-inference]\n!pip install --quiet langchain_cohere langchain_experimental\n!pip install --quiet duckduckgo-search\n!pip install --upgrade --quiet  transformers","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:37:54.358447Z","iopub.execute_input":"2024-05-14T18:37:54.359325Z","iopub.status.idle":"2024-05-14T18:41:09.353361Z","shell.execute_reply.started":"2024-05-14T18:37:54.359280Z","shell.execute_reply":"2024-05-14T18:41:09.351569Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkeras-cv 0.8.2 requires keras-core, which is not installed.\nkeras-nlp 0.9.3 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.0 which is incompatible.\njupyterlab 4.1.6 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.2 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires kubernetes<27,>=8.0.0, but you have kubernetes 29.0.0 which is incompatible.\u001b[0m\u001b[31m\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following additional packages will be installed:\n  libpoppler97 poppler-data\nSuggested packages:\n  ghostscript fonts-japanese-mincho | fonts-ipafont-mincho\n  fonts-japanese-gothic | fonts-ipafont-gothic fonts-arphic-ukai\n  fonts-arphic-uming fonts-nanum\nThe following NEW packages will be installed:\n  libpoppler97 poppler-data poppler-utils\n0 upgraded, 3 newly installed, 0 to remove and 54 not upgraded.\nNeed to get 2564 kB of archives.\nAfter this operation, 16.8 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu focal/main amd64 poppler-data all 0.4.9-2 [1475 kB]\nGet:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libpoppler97 amd64 0.86.1-0ubuntu1.4 [916 kB]\nGet:3 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 poppler-utils amd64 0.86.1-0ubuntu1.4 [174 kB]\nFetched 2564 kB in 3s (847 kB/s)        \nSelecting previously unselected package poppler-data.\n(Reading database ... 110195 files and directories currently installed.)\nPreparing to unpack .../poppler-data_0.4.9-2_all.deb ...\nUnpacking poppler-data (0.4.9-2) ...\nSelecting previously unselected package libpoppler97:amd64.\nPreparing to unpack .../libpoppler97_0.86.1-0ubuntu1.4_amd64.deb ...\nUnpacking libpoppler97:amd64 (0.86.1-0ubuntu1.4) ...\nSelecting previously unselected package poppler-utils.\nPreparing to unpack .../poppler-utils_0.86.1-0ubuntu1.4_amd64.deb ...\nUnpacking poppler-utils (0.86.1-0ubuntu1.4) ...\nSetting up libpoppler97:amd64 (0.86.1-0ubuntu1.4) ...\nSetting up poppler-data (0.4.9-2) ...\nSetting up poppler-utils (0.86.1-0ubuntu1.4) ...\nProcessing triggers for libc-bin (2.31-0ubuntu9.14) ...\nProcessing triggers for man-db (2.9.1-1) ...\nProcessing triggers for fontconfig (2.13.1-2ubuntu3) ...\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkeras-cv 0.8.2 requires keras-core, which is not installed.\nkeras-nlp 0.9.3 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\naiobotocore 2.12.3 requires botocore<1.34.70,>=1.34.41, but you have botocore 1.34.104 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\njupyterlab 4.1.6 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires kubernetes<27,>=8.0.0, but you have kubernetes 29.0.0 which is incompatible.\nkfp 2.5.0 requires urllib3<2.0.0, but you have urllib3 2.2.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.2 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\ntransformers 4.39.3 requires tokenizers<0.19,>=0.14, but you have tokenizers 0.19.1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"#from unstructured_client import UnstructuredClient\n#from unstructured_client.models import shared\n#from unstructured_client.models.errors import SDKError\n\nfrom unstructured.chunking.title import chunk_by_title\nfrom unstructured.partition.html import partition_html\nfrom unstructured.partition.pdf import partition_pdf\n#from unstructured.partition.pptx import partition_pptx\nfrom unstructured.staging.base import dict_to_elements\n#from pdf2image import convert_from_path\n\n#from pdf2image.exceptions import (\n#PDFInfoNotInstalledError,\n#PDFPageCountError,\n#PDFSyntaxError\n#)\n\nimport chromadb","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:41:09.355232Z","iopub.execute_input":"2024-05-14T18:41:09.355645Z","iopub.status.idle":"2024-05-14T18:41:15.328331Z","shell.execute_reply.started":"2024-05-14T18:41:09.355606Z","shell.execute_reply":"2024-05-14T18:41:15.327046Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"cons_GenAI = partition_html(filename=\"/kaggle/input/example-files/Generative AI_ The Next Consumer Platform _ Andreessen Horowitz.html\")\necon_GenAI = partition_html(filename=\"/kaggle/input/example-files/The Economic Case for Generative AI.html\")\npros_GenAI = partition_html(filename=\"/kaggle/input/example-files/The Future of Prosumer_ The Rise of AI Workflows .html\")","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:41:15.331647Z","iopub.execute_input":"2024-05-14T18:41:15.332433Z","iopub.status.idle":"2024-05-14T18:41:18.723089Z","shell.execute_reply.started":"2024-05-14T18:41:15.332389Z","shell.execute_reply":"2024-05-14T18:41:18.721829Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"filename = \"/kaggle/input/pdf-example/attention-is-all-you-need.pdf\"\n\npdf_elements = partition_pdf(\n    filename = \"/kaggle/input/pdf-example/attention-is-all-you-need.pdf\",\n    strategy = \"hi_res\",\n    pdf_infer_table_structure=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:42:55.295589Z","iopub.execute_input":"2024-05-14T18:42:55.296081Z","iopub.status.idle":"2024-05-14T18:42:58.498432Z","shell.execute_reply.started":"2024-05-14T18:42:55.296051Z","shell.execute_reply":"2024-05-14T18:42:58.496887Z"},"trusted":true},"execution_count":6,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/pdf-example/attention-is-all-you-need.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m pdf_elements \u001b[38;5;241m=\u001b[39m \u001b[43mpartition_pdf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/pdf-example/attention-is-all-you-need.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhi_res\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpdf_infer_table_structure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/unstructured/documents/elements.py:570\u001b[0m, in \u001b[0;36mprocess_metadata.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: _P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: _P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Element]:\n\u001b[0;32m--> 570\u001b[0m     elements \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    571\u001b[0m     sig \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(func)\n\u001b[1;32m    572\u001b[0m     params: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args)), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/unstructured/file_utils/filetype.py:622\u001b[0m, in \u001b[0;36madd_filetype.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: _P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: _P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Element]:\n\u001b[0;32m--> 622\u001b[0m     elements \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m     sig \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(func)\n\u001b[1;32m    624\u001b[0m     params: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args)), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/unstructured/file_utils/filetype.py:582\u001b[0m, in \u001b[0;36madd_metadata.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: _P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: _P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Element]:\n\u001b[0;32m--> 582\u001b[0m     elements \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    583\u001b[0m     sig \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(func)\n\u001b[1;32m    584\u001b[0m     params: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args)), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/unstructured/chunking/dispatch.py:83\u001b[0m, in \u001b[0;36madd_chunking_strategy.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m call_args\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# -- call the partitioning function to get the elements --\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m elements \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# -- look for a chunking-strategy argument --\u001b[39;00m\n\u001b[1;32m     86\u001b[0m call_args \u001b[38;5;241m=\u001b[39m get_call_args_applying_defaults()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/unstructured/partition/pdf.py:201\u001b[0m, in \u001b[0;36mpartition_pdf\u001b[0;34m(filename, file, include_page_breaks, strategy, infer_table_structure, ocr_languages, languages, include_metadata, metadata_filename, metadata_last_modified, chunking_strategy, links, hi_res_model_name, extract_images_in_pdf, extract_image_block_types, extract_image_block_output_dir, extract_image_block_to_payload, date_from_file_object, starting_page_number, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m exactly_one(filename\u001b[38;5;241m=\u001b[39mfilename, file\u001b[38;5;241m=\u001b[39mfile)\n\u001b[1;32m    199\u001b[0m languages \u001b[38;5;241m=\u001b[39m check_language_args(languages \u001b[38;5;129;01mor\u001b[39;00m [], ocr_languages) \u001b[38;5;129;01mor\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 201\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpartition_pdf_or_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_page_breaks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_page_breaks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_table_structure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_table_structure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlanguages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlanguages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata_last_modified\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata_last_modified\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhi_res_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhi_res_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_images_in_pdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_images_in_pdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_image_block_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_image_block_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_image_block_output_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_image_block_output_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_image_block_to_payload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_image_block_to_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_from_file_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_from_file_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstarting_page_number\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstarting_page_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/unstructured/partition/pdf.py:292\u001b[0m, in \u001b[0;36mpartition_pdf_or_image\u001b[0;34m(filename, file, is_image, include_page_breaks, strategy, infer_table_structure, ocr_languages, languages, metadata_last_modified, hi_res_model_name, extract_images_in_pdf, extract_image_block_types, extract_image_block_output_dir, extract_image_block_to_payload, date_from_file_object, starting_page_number, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    291\u001b[0m         warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 292\u001b[0m         elements \u001b[38;5;241m=\u001b[39m \u001b[43m_partition_pdf_or_image_local\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspooled_to_bytes_io_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m            \u001b[49m\u001b[43minfer_table_structure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_table_structure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m            \u001b[49m\u001b[43minclude_page_breaks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_page_breaks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlanguages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlanguages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata_last_modified\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata_last_modified\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlast_modification_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhi_res_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhi_res_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpdf_text_extractable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpdf_text_extractable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextract_images_in_pdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_images_in_pdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextract_image_block_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_image_block_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextract_image_block_output_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_image_block_output_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextract_image_block_to_payload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_image_block_to_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstarting_page_number\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstarting_page_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m         out_elements \u001b[38;5;241m=\u001b[39m _process_uncategorized_text_elements(elements)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m strategy \u001b[38;5;241m==\u001b[39m PartitionStrategy\u001b[38;5;241m.\u001b[39mFAST:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/unstructured/utils.py:230\u001b[0m, in \u001b[0;36mrequires_dependencies.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_deps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFollowing dependencies are missing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(missing_deps)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;241m+\u001b[39m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m         ),\n\u001b[1;32m    229\u001b[0m     )\n\u001b[0;32m--> 230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/unstructured/partition/pdf.py:422\u001b[0m, in \u001b[0;36m_partition_pdf_or_image_local\u001b[0;34m(filename, file, is_image, infer_table_structure, include_page_breaks, languages, ocr_mode, model_name, hi_res_model_name, pdf_image_dpi, metadata_last_modified, pdf_text_extractable, extract_images_in_pdf, extract_image_block_types, extract_image_block_output_dir, extract_image_block_to_payload, analysis, analyzed_image_output_dir_path, starting_page_number, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    417\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe Chipper model performs better when images are rendered with DPI >= 300 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(currently \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpdf_image_dpi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    419\u001b[0m     )\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 422\u001b[0m     inferred_document_layout \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_file_with_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhi_res_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpdf_image_dpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpdf_image_dpi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hi_res_model_name\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchipper\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    430\u001b[0m         \u001b[38;5;66;03m# NOTE(alan): We shouldn't do OCR with chipper\u001b[39;00m\n\u001b[1;32m    431\u001b[0m         \u001b[38;5;66;03m# NOTE(antonio): We shouldn't do PDFMiner with chipper\u001b[39;00m\n\u001b[1;32m    432\u001b[0m         final_document_layout \u001b[38;5;241m=\u001b[39m inferred_document_layout\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/unstructured_inference/inference/layout.py:396\u001b[0m, in \u001b[0;36mprocess_file_with_model\u001b[0;34m(filename, model_name, is_image, fixed_layouts, pdf_image_dpi, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported model type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    388\u001b[0m layout \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    389\u001b[0m     DocumentLayout\u001b[38;5;241m.\u001b[39mfrom_image_file(\n\u001b[1;32m    390\u001b[0m         filename,\n\u001b[1;32m    391\u001b[0m         detection_model\u001b[38;5;241m=\u001b[39mdetection_model,\n\u001b[1;32m    392\u001b[0m         element_extraction_model\u001b[38;5;241m=\u001b[39melement_extraction_model,\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    394\u001b[0m     )\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_image\n\u001b[0;32m--> 396\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mDocumentLayout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdetection_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetection_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43melement_extraction_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43melement_extraction_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfixed_layouts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_layouts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpdf_image_dpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpdf_image_dpi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m )\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m layout\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/unstructured_inference/inference/layout.py:78\u001b[0m, in \u001b[0;36mDocumentLayout.from_file\u001b[0;34m(cls, filename, fixed_layouts, pdf_image_dpi, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     fixed_layouts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, number_of_pages)]\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (image_path, fixed_layout) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(image_paths, fixed_layouts)):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m# NOTE(robinson) - In the future, maybe we detect the page number and default\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m# to the index if it is not detected\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m image:\n\u001b[1;32m     79\u001b[0m         page \u001b[38;5;241m=\u001b[39m PageLayout\u001b[38;5;241m.\u001b[39mfrom_image(\n\u001b[1;32m     80\u001b[0m             image,\n\u001b[1;32m     81\u001b[0m             number\u001b[38;5;241m=\u001b[39mi \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     85\u001b[0m         )\n\u001b[1;32m     86\u001b[0m         pages\u001b[38;5;241m.\u001b[39mappend(page)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/Image.py:3298\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3296\u001b[0m     init()\n\u001b[1;32m   3297\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3298\u001b[0m     factory, accept \u001b[38;5;241m=\u001b[39m OPEN[i]\n\u001b[1;32m   3299\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m accept \u001b[38;5;129;01mor\u001b[39;00m accept(prefix)\n\u001b[1;32m   3300\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(result) \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m]:\n","\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file '/tmp/tmpyg9uebqs/effcd4e2-eb69-4767-a86a-05525cf4759b-01.ppm'"],"ename":"UnidentifiedImageError","evalue":"cannot identify image file '/tmp/tmpyg9uebqs/effcd4e2-eb69-4767-a86a-05525cf4759b-01.ppm'","output_type":"error"}]},{"cell_type":"code","source":"#Remove the footers and references\nfooters = [item for item in pdf_elements if item.category==\"Footer\"]\nreference = [item for item in pdf_elements if item.category==\"Title\" and item.text==\"References\"]\nreference_id = reference[0].to_dict()['element_id']\nreference_pg = reference[0].to_dict()['metadata']['page_number']\nreference_items = [item for item in pdf_elements if item.metadata.parent_id == reference_id or item.metadata.page_number>reference_pg]\npdf_adj_elements = [item for item in pdf_elements if item not in footers+reference+reference_items]","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:41:37.766208Z","iopub.status.idle":"2024-05-14T18:41:37.766647Z","shell.execute_reply.started":"2024-05-14T18:41:37.766442Z","shell.execute_reply":"2024-05-14T18:41:37.766460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"el_set = set()\nfor el in pdf_adj_elements:\n    el_set.add(el.category)\nprint(el_set)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:41:37.768033Z","iopub.status.idle":"2024-05-14T18:41:37.768422Z","shell.execute_reply.started":"2024-05-14T18:41:37.768232Z","shell.execute_reply":"2024-05-14T18:41:37.768248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Chunk by title and add to ChromaDB\nelements = chunk_by_title(pdf_adj_elements+cons_GenAI+econ_GenAI+pros_GenAI)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:41:37.769754Z","iopub.status.idle":"2024-05-14T18:41:37.771015Z","shell.execute_reply.started":"2024-05-14T18:41:37.770707Z","shell.execute_reply":"2024-05-14T18:41:37.770732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from langchain_community.vectorstores import Chroma\nfrom langchain_core.documents import Document\n\ndocuments=[]\nfor el in elements:\n    metadata = el.metadata.to_dict()\n    filtered_metadata = {}\n    del metadata['languages']\n    for key,value in metadata.items():\n        if isinstance(value,list):\n            continue\n        else:\n            filtered_metadata[key] = value\n    filtered_metadata['source'] = filtered_metadata['filename']\n    documents.append(Document(page_content = el.text,metadata = filtered_metadata))","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:41:37.772745Z","iopub.status.idle":"2024-05-14T18:41:37.773291Z","shell.execute_reply.started":"2024-05-14T18:41:37.773022Z","shell.execute_reply":"2024-05-14T18:41:37.773044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LLM\nimport os\nos.environ['COHERE_API_KEY'] = '4wxxCfBV3K2rj33RYQVOZMZ9DtWVvgmI57noCUFF'","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:41:37.775914Z","iopub.status.idle":"2024-05-14T18:41:37.776305Z","shell.execute_reply.started":"2024-05-14T18:41:37.776122Z","shell.execute_reply":"2024-05-14T18:41:37.776138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from langchain_cohere import CohereEmbeddings\nembd = CohereEmbeddings()\nvectorstore = Chroma.from_documents(documents=documents,embedding=embd)\nvector_retriever = vectorstore.as_retriever(\n    search_type='similarity',\n    search_kwargs = {\"k\":5}\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:41:37.777618Z","iopub.status.idle":"2024-05-14T18:41:37.778418Z","shell.execute_reply.started":"2024-05-14T18:41:37.778207Z","shell.execute_reply":"2024-05-14T18:41:37.778226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Set up a tool to access the vector data store\nfrom langchain.tools.retriever import create_retriever_tool\nvectorstore_search = create_retriever_tool(\n    retriever=vector_retriever,\n    name=\"GenAI_content_expert\",\n    description=\"Retrieve relevant information from a vectorstore that contains expert information on GenAI and its industry usage\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:41:37.779738Z","iopub.status.idle":"2024-05-14T18:41:37.780104Z","shell.execute_reply.started":"2024-05-14T18:41:37.779926Z","shell.execute_reply":"2024-05-14T18:41:37.779941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Set up a tool to access internet search results\nfrom langchain_community.tools import DuckDuckGoSearchResults\ninternet_search = DuckDuckGoSearchResults()\ninternet_search.name = \"internet_search\"\ninternet_search.description = \"Returns a list of relevant document snippets for a textual query retrieved from the internet.\"\n\nfrom langchain_core.pydantic_v1 import BaseModel,Field\nclass DDGoSearchInput(BaseModel):\n    query: str = Field(description=\"Query to search the internet with\")\ninternet_search.args_schema = DDGoSearchInput","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:41:37.781381Z","iopub.status.idle":"2024-05-14T18:41:37.781764Z","shell.execute_reply.started":"2024-05-14T18:41:37.781572Z","shell.execute_reply":"2024-05-14T18:41:37.781587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Set up a tool to execute a python script\nfrom langchain.agents import Tool\nfrom langchain_experimental.utilities import PythonREPL\n\npython_repl = PythonREPL()\npython_tool = Tool(\n    name=\"python_repl\",\n    description=\"Executes python code and returns the result. The code runs in a static sandbox without interactive mode, so print output or save output to a file.\",\n    func=python_repl.run,\n)\npython_tool.name = \"python_interpreter\"\n\nfrom langchain_core.pydantic_v1 import BaseModel, Field\nclass ToolInput(BaseModel):\n    code: str = Field(description=\"Python code to execute.\")\npython_tool.args_schema = ToolInput","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:41:37.782743Z","iopub.status.idle":"2024-05-14T18:41:37.783097Z","shell.execute_reply.started":"2024-05-14T18:41:37.782917Z","shell.execute_reply":"2024-05-14T18:41:37.782932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from langchain.agents import AgentExecutor\nfrom langchain_cohere.react_multi_hop.agent import create_cohere_react_agent\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_cohere.chat_models import ChatCohere","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:41:37.784063Z","iopub.status.idle":"2024-05-14T18:41:37.784425Z","shell.execute_reply.started":"2024-05-14T18:41:37.784239Z","shell.execute_reply":"2024-05-14T18:41:37.784253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create an agent using the Cohere ReAct framework with access to the relevant tools for executing planned multi-tool use design pattern\nllm = ChatCohere(model='command-r-plus',temperature=0.3)\n\n#Preamble\npreamble = \"\"\"\nYou are a learning companion who answers any questions that the user has on the field of Generative AI and generates the relevant results.\nYou can access a query augmenter to generate multiple questions that exhaustively probe on different aspects of query shared by the user. \nYou are equipped with a vectorstore to search for the relevant information in crafting a response to the multiple questions generated.\nYou are also equipped with an internet search tool to look up the information if the vectorstore provides limited context.\nIf some numerical calculations or visualizations are required, you are equipped with the python interpreter for generating the results.\nIf the user asks for something not related to generative AI, please politely draw attention towards the objective of learning generative AI\n\"\"\"\n\nprompt = ChatPromptTemplate.from_template('{input}')","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:41:37.786301Z","iopub.status.idle":"2024-05-14T18:41:37.786971Z","shell.execute_reply.started":"2024-05-14T18:41:37.786730Z","shell.execute_reply":"2024-05-14T18:41:37.786747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from langchain.chains import LLMChain\nfrom langchain_core.tools import tool\n\n@tool\ndef expand_query(query):\n    \"\"\"Augments the given query by generating multiple related questions that would more reliably cover the vector embedding search space\"\"\"\n    expand_prompt = ChatPromptTemplate.from_template(\"\"\"You are an assistant that helps generate the relevant educational content based on user requirements.\n        For the query enclosed in triple backticks, please suggest five additional questions related to the context of the information requested.\n        Suggest only short questions without compound sentences. Make sure that the questions touch upon different aspects of the query.\n        Output one question per line and append a ? symbol at the end of every question. Do not number the questions\n        ```{query}```\"\"\")\n    augment_chain = LLMChain(llm=llm,prompt=expand_prompt)\n    response = augment_chain.run(query)\n    return response.split('\\n\\n')\n    \nexpand_query.name = \"expand_query\"\nexpand_query.description = \"Augments the given query by generating multiple related questions that would more reliably cover the vector embedding search space\"\n\nfrom langchain_core.pydantic_v1 import BaseModel, Field\nclass primary_query(BaseModel):\n    query: str = Field(description=\"The original query corresponding to user input\")\nexpand_query.args_schema = primary_query\n\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:41:37.788067Z","iopub.status.idle":"2024-05-14T18:41:37.788427Z","shell.execute_reply.started":"2024-05-14T18:41:37.788248Z","shell.execute_reply":"2024-05-14T18:41:37.788262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"agent = create_cohere_react_agent(\n    llm = llm,\n    prompt=prompt,\n    tools=[expand_query,vectorstore_search,internet_search,python_tool]\n)\n\nagent_executor = AgentExecutor(agent=agent,tools=[expand_query,vectorstore_search,internet_search,python_tool],verbose=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:41:37.789466Z","iopub.status.idle":"2024-05-14T18:41:37.789834Z","shell.execute_reply.started":"2024-05-14T18:41:37.789642Z","shell.execute_reply":"2024-05-14T18:41:37.789656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"response = agent_executor.invoke({\n    \"input\":\"Please share details on the history of transformer model development with information on the forefathers\",\n    \"preamble\":preamble\n})","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:41:37.790862Z","iopub.status.idle":"2024-05-14T18:41:37.791214Z","shell.execute_reply.started":"2024-05-14T18:41:37.791038Z","shell.execute_reply":"2024-05-14T18:41:37.791053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"response['output']","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:41:37.792604Z","iopub.status.idle":"2024-05-14T18:41:37.793044Z","shell.execute_reply.started":"2024-05-14T18:41:37.792849Z","shell.execute_reply":"2024-05-14T18:41:37.792869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import load_tool\ntts_tool = load_tool(\"text-to-speech\")\ntts_tool(response['output'])","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:41:37.794430Z","iopub.status.idle":"2024-05-14T18:41:37.794858Z","shell.execute_reply.started":"2024-05-14T18:41:37.794640Z","shell.execute_reply":"2024-05-14T18:41:37.794657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def summarize_result(descriptive_output):\n    \"\"\"Summarizes the result of the LLM in the form of multiple bullets that are easier for a reader to grasp\"\"\"\n    summary_bullets = ChatPromptTemplate.from_template(\"\"\"You are a conversation summarizer that produces a set of bullets\n    to better lay out the context of a longer descriptive text enclosed in triple backticks. Please mention the central theme of the conversation\n    at the beginning and follow that with short bullets each reinforcing the message in the central theme```{descriptive_output}```\"\"\")\n    summarizer = LLMChain(llm=llm,prompt=summary_bullets)\n    response = summarizer.run(descriptive_output)\n    return response","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:41:37.796506Z","iopub.status.idle":"2024-05-14T18:41:37.796949Z","shell.execute_reply.started":"2024-05-14T18:41:37.796716Z","shell.execute_reply":"2024-05-14T18:41:37.796732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summarize_result(response['output'])","metadata":{"execution":{"iopub.status.busy":"2024-05-14T18:41:37.798293Z","iopub.status.idle":"2024-05-14T18:41:37.798649Z","shell.execute_reply.started":"2024-05-14T18:41:37.798470Z","shell.execute_reply":"2024-05-14T18:41:37.798484Z"},"trusted":true},"execution_count":null,"outputs":[]}]}