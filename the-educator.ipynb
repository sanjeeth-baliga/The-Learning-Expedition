{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8308438,"sourceType":"datasetVersion","datasetId":4935173},{"sourceId":8308505,"sourceType":"datasetVersion","datasetId":4935219}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-05T10:44:34.065995Z","iopub.execute_input":"2024-05-05T10:44:34.066439Z","iopub.status.idle":"2024-05-05T10:44:34.581104Z","shell.execute_reply.started":"2024-05-05T10:44:34.066407Z","shell.execute_reply":"2024-05-05T10:44:34.579815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Warning control\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-05-05T10:44:37.875380Z","iopub.execute_input":"2024-05-05T10:44:37.876066Z","iopub.status.idle":"2024-05-05T10:44:37.881855Z","shell.execute_reply.started":"2024-05-05T10:44:37.876022Z","shell.execute_reply":"2024-05-05T10:44:37.880219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --quiet unstructured","metadata":{"execution":{"iopub.status.busy":"2024-05-05T10:44:42.505266Z","iopub.execute_input":"2024-05-05T10:44:42.506024Z","iopub.status.idle":"2024-05-05T10:44:58.936531Z","shell.execute_reply.started":"2024-05-05T10:44:42.505976Z","shell.execute_reply":"2024-05-05T10:44:58.934949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --quiet chromadb","metadata":{"execution":{"iopub.status.busy":"2024-05-05T10:44:58.939185Z","iopub.execute_input":"2024-05-05T10:44:58.939609Z","iopub.status.idle":"2024-05-05T10:45:16.165044Z","shell.execute_reply.started":"2024-05-05T10:44:58.939573Z","shell.execute_reply":"2024-05-05T10:45:16.163909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!apt-get install poppler-utils -y","metadata":{"execution":{"iopub.status.busy":"2024-05-05T10:45:33.301670Z","iopub.execute_input":"2024-05-05T10:45:33.302217Z","iopub.status.idle":"2024-05-05T10:45:37.072084Z","shell.execute_reply.started":"2024-05-05T10:45:33.302169Z","shell.execute_reply":"2024-05-05T10:45:37.070501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --quiet --upgrade unstructured[local-inference]","metadata":{"execution":{"iopub.status.busy":"2024-05-05T10:45:43.106755Z","iopub.execute_input":"2024-05-05T10:45:43.107236Z","iopub.status.idle":"2024-05-05T10:46:01.503863Z","shell.execute_reply.started":"2024-05-05T10:45:43.107186Z","shell.execute_reply":"2024-05-05T10:46:01.502349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from unstructured_client import UnstructuredClient\n#from unstructured_client.models import shared\n#from unstructured_client.models.errors import SDKError\n\nfrom unstructured.chunking.title import chunk_by_title\nfrom unstructured.partition.html import partition_html\nfrom unstructured.partition.pdf import partition_pdf\n#from unstructured.partition.pptx import partition_pptx\nfrom unstructured.staging.base import dict_to_elements\n#from pdf2image import convert_from_path\n\n#from pdf2image.exceptions import (\n#PDFInfoNotInstalledError,\n#PDFPageCountError,\n#PDFSyntaxError\n#)\n\nimport chromadb","metadata":{"execution":{"iopub.status.busy":"2024-05-05T10:46:01.505900Z","iopub.execute_input":"2024-05-05T10:46:01.506318Z","iopub.status.idle":"2024-05-05T10:46:05.449230Z","shell.execute_reply.started":"2024-05-05T10:46:01.506284Z","shell.execute_reply":"2024-05-05T10:46:05.448075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cons_GenAI = partition_html(filename=\"/kaggle/input/example-files/Generative AI_ The Next Consumer Platform _ Andreessen Horowitz.html\")\necon_GenAI = partition_html(filename=\"/kaggle/input/example-files/The Economic Case for Generative AI.html\")\npros_GenAI = partition_html(filename=\"/kaggle/input/example-files/The Future of Prosumer_ The Rise of AI Workflows .html\")","metadata":{"execution":{"iopub.status.busy":"2024-05-05T10:46:09.715292Z","iopub.execute_input":"2024-05-05T10:46:09.716452Z","iopub.status.idle":"2024-05-05T10:46:13.267771Z","shell.execute_reply.started":"2024-05-05T10:46:09.716403Z","shell.execute_reply":"2024-05-05T10:46:13.266407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filename = \"/kaggle/input/pdf-example/attention-is-all-you-need.pdf\"\n\npdf_elements = partition_pdf(\n    filename = \"/kaggle/input/pdf-example/attention-is-all-you-need.pdf\",\n    strategy = \"hi_res\",\n    pdf_infer_table_structure=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T10:46:26.975349Z","iopub.execute_input":"2024-05-05T10:46:26.975982Z","iopub.status.idle":"2024-05-05T10:48:06.775423Z","shell.execute_reply.started":"2024-05-05T10:46:26.975936Z","shell.execute_reply":"2024-05-05T10:48:06.773880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Remove the footers and references\nfooters = [item for item in pdf_elements if item.category==\"Footer\"]\nreference = [item for item in pdf_elements if item.category==\"Title\" and item.text==\"References\"]\nreference_id = reference[0].to_dict()['element_id']\nreference_pg = reference[0].to_dict()['metadata']['page_number']\nreference_items = [item for item in pdf_elements if item.metadata.parent_id == reference_id or item.metadata.page_number>reference_pg]\npdf_adj_elements = [item for item in pdf_elements if item not in footers+reference+reference_items]","metadata":{"execution":{"iopub.status.busy":"2024-05-05T10:48:21.256611Z","iopub.execute_input":"2024-05-05T10:48:21.258217Z","iopub.status.idle":"2024-05-05T10:48:21.290207Z","shell.execute_reply.started":"2024-05-05T10:48:21.258146Z","shell.execute_reply":"2024-05-05T10:48:21.288833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"el_set = set()\nfor el in pdf_adj_elements:\n    el_set.add(el.category)\nprint(el_set)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T10:49:36.213901Z","iopub.execute_input":"2024-05-05T10:49:36.214366Z","iopub.status.idle":"2024-05-05T10:49:36.222495Z","shell.execute_reply.started":"2024-05-05T10:49:36.214324Z","shell.execute_reply":"2024-05-05T10:49:36.220327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Chunk by title and add to ChromaDB\nelements = chunk_by_title(pdf_adj_elements+cons_GenAI+econ_GenAI+pros_GenAI)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T10:51:13.750995Z","iopub.execute_input":"2024-05-05T10:51:13.751452Z","iopub.status.idle":"2024-05-05T10:51:13.796214Z","shell.execute_reply.started":"2024-05-05T10:51:13.751420Z","shell.execute_reply":"2024-05-05T10:51:13.794182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install --quiet langchain_cohere langchain_experimental\n#! pip install --upgrade --quiet  transformers huggingface_hub","metadata":{"execution":{"iopub.status.busy":"2024-05-12T18:22:53.622410Z","iopub.execute_input":"2024-05-12T18:22:53.622802Z","iopub.status.idle":"2024-05-12T18:23:27.745097Z","shell.execute_reply.started":"2024-05-12T18:22:53.622769Z","shell.execute_reply":"2024-05-12T18:23:27.743818Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkeras-cv 0.8.2 requires keras-core, which is not installed.\nkeras-nlp 0.9.3 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\naiobotocore 2.12.3 requires botocore<1.34.70,>=1.34.41, but you have botocore 1.34.103 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\njupyterlab 4.1.6 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires urllib3<2.0.0, but you have urllib3 2.2.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.2 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\ntransformers 4.39.3 requires tokenizers<0.19,>=0.14, but you have tokenizers 0.19.1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from langchain_community.vectorstores import Chroma\nfrom langchain_core.documents import Document\n\ndocuments=[]\nfor el in elements:\n    metadata = el.metadata.to_dict()\n    filtered_metadata = {}\n    del metadata['languages']\n    for key,value in metadata.items():\n        if isinstance(value,list):\n            continue\n        else:\n            filtered_metadata[key] = value\n    filtered_metadata['source'] = filtered_metadata['filename']\n    documents.append(Document(page_content = el.text,metadata = filtered_metadata))","metadata":{"execution":{"iopub.status.busy":"2024-05-05T11:35:25.462759Z","iopub.execute_input":"2024-05-05T11:35:25.463211Z","iopub.status.idle":"2024-05-05T11:35:25.784605Z","shell.execute_reply.started":"2024-05-05T11:35:25.463180Z","shell.execute_reply":"2024-05-05T11:35:25.782923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LLM\nimport os\nos.environ['COHERE_API_KEY'] = '4wxxCfBV3K2rj33RYQVOZMZ9DtWVvgmI57noCUFF'","metadata":{"execution":{"iopub.status.busy":"2024-05-12T18:23:27.751757Z","iopub.execute_input":"2024-05-12T18:23:27.752064Z","iopub.status.idle":"2024-05-12T18:23:27.758439Z","shell.execute_reply.started":"2024-05-12T18:23:27.752033Z","shell.execute_reply":"2024-05-12T18:23:27.757290Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from langchain_cohere import CohereEmbeddings\nembd = CohereEmbeddings()\nvectorstore = Chroma.from_documents(documents=documents,embedding=embd)\nvector_retriever = vectorstore.as_retriever(\n    search_type='similarity',\n    search_kwargs = {\"k\":5}\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T11:36:12.352551Z","iopub.execute_input":"2024-05-05T11:36:12.353037Z","iopub.status.idle":"2024-05-05T11:36:27.783252Z","shell.execute_reply.started":"2024-05-05T11:36:12.353004Z","shell.execute_reply":"2024-05-05T11:36:27.781827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Set up a tool to access the vector data store\nfrom langchain.tools.retriever import create_retriever_tool\nvectorstore_search = create_retriever_tool(\n    retriever=vector_retriever,\n    name=\"GenAI_content_expert\",\n    description=\"Retrieve relevant information from a vectorstore that contains expert information on GenAI and its industry usage\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T11:36:30.312762Z","iopub.execute_input":"2024-05-05T11:36:30.313765Z","iopub.status.idle":"2024-05-05T11:36:30.320110Z","shell.execute_reply.started":"2024-05-05T11:36:30.313709Z","shell.execute_reply":"2024-05-05T11:36:30.318844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --quiet duckduckgo-search","metadata":{"execution":{"iopub.status.busy":"2024-05-05T11:36:34.172639Z","iopub.execute_input":"2024-05-05T11:36:34.173817Z","iopub.status.idle":"2024-05-05T11:36:51.336999Z","shell.execute_reply.started":"2024-05-05T11:36:34.173767Z","shell.execute_reply":"2024-05-05T11:36:51.335012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Set up a tool to access internet search results\nfrom langchain_community.tools import DuckDuckGoSearchResults\ninternet_search = DuckDuckGoSearchResults()\ninternet_search.name = \"internet_search\"\ninternet_search.description = \"Returns a list of relevant document snippets for a textual query retrieved from the internet.\"\n\nfrom langchain_core.pydantic_v1 import BaseModel,Field\nclass DDGoSearchInput(BaseModel):\n    query: str = Field(description=\"Query to search the internet with\")\ninternet_search.args_schema = DDGoSearchInput","metadata":{"execution":{"iopub.status.busy":"2024-05-05T11:40:33.513948Z","iopub.execute_input":"2024-05-05T11:40:33.514515Z","iopub.status.idle":"2024-05-05T11:40:33.617651Z","shell.execute_reply.started":"2024-05-05T11:40:33.514474Z","shell.execute_reply":"2024-05-05T11:40:33.616336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Set up a tool to execute a python script\nfrom langchain.agents import Tool\nfrom langchain_experimental.utilities import PythonREPL\n\npython_repl = PythonREPL()\npython_tool = Tool(\n    name=\"python_repl\",\n    description=\"Executes python code and returns the result. The code runs in a static sandbox without interactive mode, so print output or save output to a file.\",\n    func=python_repl.run,\n)\npython_tool.name = \"python_interpreter\"\n\nfrom langchain_core.pydantic_v1 import BaseModel, Field\nclass ToolInput(BaseModel):\n    code: str = Field(description=\"Python code to execute.\")\npython_tool.args_schema = ToolInput","metadata":{"execution":{"iopub.status.busy":"2024-05-05T11:40:37.932801Z","iopub.execute_input":"2024-05-05T11:40:37.933273Z","iopub.status.idle":"2024-05-05T11:40:37.952028Z","shell.execute_reply.started":"2024-05-05T11:40:37.933237Z","shell.execute_reply":"2024-05-05T11:40:37.950557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from langchain.agents import AgentExecutor\nfrom langchain_cohere.react_multi_hop.agent import create_cohere_react_agent\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_cohere.chat_models import ChatCohere","metadata":{"execution":{"iopub.status.busy":"2024-05-12T18:23:27.760752Z","iopub.execute_input":"2024-05-12T18:23:27.761103Z","iopub.status.idle":"2024-05-12T18:23:29.845896Z","shell.execute_reply.started":"2024-05-12T18:23:27.761067Z","shell.execute_reply":"2024-05-12T18:23:29.844974Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#Create an agent using the Cohere ReAct framework with access to the relevant tools for executing planned multi-tool use design pattern\nllm = ChatCohere(model='command-r-plus',temperature=0.3)\n\n#Preamble\npreamble = \"\"\"\nYou are a learning companion who answers any questions that the user has on the field of Generative AI and generates the relevant results.\nYou are equipped with a vectorstore to search for the relevant information in crafting an understandable response.\nYou are also equipped with an internet search tool to look up the information if the vectorstore provides limited context.\nIf some numerical calculations or visualizations are required, you are equipped with the python interpreter for generating the results.\nYou also have a text to speech tool to generate audio output.\nIf the user asks for something not related to generative AI, please politely draw attention towards the objective of learning generative AI\n\"\"\"\n\nprompt = ChatPromptTemplate.from_template('{input}')","metadata":{"execution":{"iopub.status.busy":"2024-05-12T18:23:58.721003Z","iopub.execute_input":"2024-05-12T18:23:58.721733Z","iopub.status.idle":"2024-05-12T18:23:58.767161Z","shell.execute_reply.started":"2024-05-12T18:23:58.721680Z","shell.execute_reply":"2024-05-12T18:23:58.766000Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from langchain.chains import LLMChain\nfrom langchain_core.tools import tool\n\n@tool\ndef expand_query(query):\n    \"\"\"Augments the given query by generating multiple related questions that would more reliably cover the vector embedding search space\"\"\"\n    expand_prompt = ChatPromptTemplate.from_template(\"\"\"You are an assistant that helps generate the relevant educational content based on user requirements.\n        For the query enclosed in triple backticks, please suggest five additional questions related to the context of the information requested.\n        Suggest only short questions without compound sentences. Make sure that the questions touch upon different aspects of the query.\n        Output one question per line and append a ? symbol at the end of every question. Do not number the questions\n        ```{query}```\"\"\")\n    augment_chain = LLMChain(llm=llm,prompt=expand_prompt)\n    response = augment_chain.run(query)\n    return response.split('\\n\\n')\n    \nexpand_query.name = \"augment_query_with_expansion\"\nexpand_query.description = \"Augments the given query by generating multiple related questions that would more reliably cover the vector embedding search space\"\n\nfrom langchain_core.pydantic_v1 import BaseModel, Field\nclass primary_query(BaseModel):\n    query: str = Field(description=\"The original query corresponding to user input\")\nexpand_query.args_schema = primary_query","metadata":{"execution":{"iopub.status.busy":"2024-05-12T19:07:16.064193Z","iopub.execute_input":"2024-05-12T19:07:16.064557Z","iopub.status.idle":"2024-05-12T19:07:16.078100Z","shell.execute_reply.started":"2024-05-12T19:07:16.064530Z","shell.execute_reply":"2024-05-12T19:07:16.077191Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"agent = create_cohere_react_agent(\n    llm = llm,\n    prompt=prompt,\n    tools=[vectorstore_search,internet_search,python_tool,tts_co_tool]\n)\n\nagent_executor = AgentExecutor(agent=agent,tools=[vectorstore_search,internet_search,python_tool,tts_co_tool],verbose=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T11:54:23.624897Z","iopub.execute_input":"2024-05-05T11:54:23.625347Z","iopub.status.idle":"2024-05-05T11:54:23.640213Z","shell.execute_reply.started":"2024-05-05T11:54:23.625315Z","shell.execute_reply":"2024-05-05T11:54:23.638554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"response = agent_executor.invoke({\n    \"input\":\"What was the very first LLM model designed and how long ago was it designed?\",\n    \"preamble\":preamble\n})\n\nresponse","metadata":{"execution":{"iopub.status.busy":"2024-05-05T11:55:59.015472Z","iopub.execute_input":"2024-05-05T11:55:59.016411Z","iopub.status.idle":"2024-05-05T11:56:08.649876Z","shell.execute_reply.started":"2024-05-05T11:55:59.016354Z","shell.execute_reply":"2024-05-05T11:56:08.648528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"response['output']","metadata":{"execution":{"iopub.status.busy":"2024-05-05T11:56:31.995513Z","iopub.execute_input":"2024-05-05T11:56:31.996020Z","iopub.status.idle":"2024-05-05T11:56:32.005014Z","shell.execute_reply.started":"2024-05-05T11:56:31.995982Z","shell.execute_reply":"2024-05-05T11:56:32.003314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import load_tool\ntts_tool = load_tool(\"text-to-speech\")\ntts_tool(response['output'])","metadata":{"execution":{"iopub.status.busy":"2024-05-05T11:57:19.825769Z","iopub.execute_input":"2024-05-05T11:57:19.826237Z","iopub.status.idle":"2024-05-05T11:57:28.296776Z","shell.execute_reply.started":"2024-05-05T11:57:19.826205Z","shell.execute_reply":"2024-05-05T11:57:28.295720Z"},"trusted":true},"execution_count":null,"outputs":[]}]}